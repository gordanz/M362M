<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 More about Random Walks | Lecture notes for &quot;Introduction to Stochastic Processes&quot;</title>
  <meta name="description" content="A set of lecture notes for M362M: Introduction to Stochastic Processes" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 More about Random Walks | Lecture notes for &quot;Introduction to Stochastic Processes&quot;" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A set of lecture notes for M362M: Introduction to Stochastic Processes" />
  <meta name="github-repo" content="gordanz/M362M" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 More about Random Walks | Lecture notes for &quot;Introduction to Stochastic Processes&quot;" />
  
  <meta name="twitter:description" content="A set of lecture notes for M362M: Introduction to Stochastic Processes" />
  

<meta name="author" content="Gordan Zitkovic" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="random-walks.html"/>
<link rel="next" href="dist.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">M362M Lecture notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> An intro to R and RStudio</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#setting-up-an-r-environment-on-your-computer"><i class="fa fa-check"></i><b>1.1</b> Setting up an R environment on your computer</a><ul>
<li class="chapter" data-level="1.1.1" data-path="intro.html"><a href="intro.html#installing-r"><i class="fa fa-check"></i><b>1.1.1</b> Installing R</a></li>
<li class="chapter" data-level="1.1.2" data-path="intro.html"><a href="intro.html#installing-rstudio"><i class="fa fa-check"></i><b>1.1.2</b> Installing RStudio</a></li>
<li class="chapter" data-level="1.1.3" data-path="intro.html"><a href="intro.html#installing-basic-packages"><i class="fa fa-check"></i><b>1.1.3</b> Installing basic packages</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#learning-the-basics-of-r"><i class="fa fa-check"></i><b>1.2</b> Learning the basics of R</a><ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#the-console-scripts-and-r-notebooks"><i class="fa fa-check"></i><b>1.2.1</b> The console, Scripts and R Notebooks</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#asking-for-help"><i class="fa fa-check"></i><b>1.2.2</b> Asking for help</a></li>
<li class="chapter" data-level="1.2.3" data-path="intro.html"><a href="intro.html#vectors"><i class="fa fa-check"></i><b>1.2.3</b> Vectors</a></li>
<li class="chapter" data-level="1.2.4" data-path="intro.html"><a href="intro.html#matrices"><i class="fa fa-check"></i><b>1.2.4</b> Matrices</a></li>
<li class="chapter" data-level="1.2.5" data-path="intro.html"><a href="intro.html#functions"><i class="fa fa-check"></i><b>1.2.5</b> Functions</a></li>
<li class="chapter" data-level="1.2.6" data-path="intro.html"><a href="intro.html#if-else-statements"><i class="fa fa-check"></i><b>1.2.6</b> If-else statements</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#problems"><i class="fa fa-check"></i><b>1.3</b> Problems</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="simulation-of-random-variables-and-monte-carlo.html"><a href="simulation-of-random-variables-and-monte-carlo.html"><i class="fa fa-check"></i><b>2</b> Simulation of Random Variables and Monte Carlo</a><ul>
<li class="chapter" data-level="2.1" data-path="simulation-of-random-variables-and-monte-carlo.html"><a href="simulation-of-random-variables-and-monte-carlo.html#simulation-of-some-common-probability-distributions"><i class="fa fa-check"></i><b>2.1</b> Simulation of some common probability distributions</a></li>
<li class="chapter" data-level="2.2" data-path="simulation-of-random-variables-and-monte-carlo.html"><a href="simulation-of-random-variables-and-monte-carlo.html#multivariate-distributions"><i class="fa fa-check"></i><b>2.2</b> Multivariate Distributions</a></li>
<li class="chapter" data-level="2.3" data-path="simulation-of-random-variables-and-monte-carlo.html"><a href="simulation-of-random-variables-and-monte-carlo.html#monte-carlo"><i class="fa fa-check"></i><b>2.3</b> Monte Carlo</a></li>
<li class="chapter" data-level="2.4" data-path="simulation-of-random-variables-and-monte-carlo.html"><a href="simulation-of-random-variables-and-monte-carlo.html#conditional-distributions"><i class="fa fa-check"></i><b>2.4</b> Conditional distributions</a></li>
<li class="chapter" data-level="2.5" data-path="simulation-of-random-variables-and-monte-carlo.html"><a href="simulation-of-random-variables-and-monte-carlo.html#additional-problems-for-chapter-2"><i class="fa fa-check"></i><b>2.5</b> Additional Problems for Chapter 2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="random-walks.html"><a href="random-walks.html"><i class="fa fa-check"></i><b>3</b> Random Walks</a><ul>
<li class="chapter" data-level="3.1" data-path="random-walks.html"><a href="random-walks.html#what-are-stochastic-processes"><i class="fa fa-check"></i><b>3.1</b> What are stochastic processes?</a></li>
<li class="chapter" data-level="3.2" data-path="random-walks.html"><a href="random-walks.html#the-simple-symmetric-random-walk"><i class="fa fa-check"></i><b>3.2</b> The Simple Symmetric Random Walk</a></li>
<li class="chapter" data-level="3.3" data-path="random-walks.html"><a href="random-walks.html#how-to-simulate-random-walks"><i class="fa fa-check"></i><b>3.3</b> How to simulate random walks</a></li>
<li class="chapter" data-level="3.4" data-path="random-walks.html"><a href="random-walks.html#two-ways-of-looking-at-a-stochastic-proceses"><i class="fa fa-check"></i><b>3.4</b> Two ways of looking at a stochastic proceses</a><ul>
<li class="chapter" data-level="3.4.1" data-path="random-walks.html"><a href="random-walks.html#column-wise-distributionally"><i class="fa fa-check"></i><b>3.4.1</b> Column-wise (distributionally)</a></li>
<li class="chapter" data-level="3.4.2" data-path="random-walks.html"><a href="random-walks.html#row-wise-trajectorially-or-path-wise"><i class="fa fa-check"></i><b>3.4.2</b> Row-wise (trajectorially or path-wise)</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="random-walks.html"><a href="random-walks.html#the-path-space"><i class="fa fa-check"></i><b>3.5</b> The path space</a></li>
<li class="chapter" data-level="3.6" data-path="random-walks.html"><a href="random-walks.html#the-distribution-of-x_n"><i class="fa fa-check"></i><b>3.6</b> The distribution of <span class="math inline">\(X_n\)</span></a></li>
<li class="chapter" data-level="3.7" data-path="random-walks.html"><a href="random-walks.html#biased-random-walks"><i class="fa fa-check"></i><b>3.7</b> Biased random walks</a></li>
<li class="chapter" data-level="3.8" data-path="random-walks.html"><a href="random-walks.html#additional-problems-for-chapter-3"><i class="fa fa-check"></i><b>3.8</b> Additional problems for Chapter 3</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="more-about-random-walks.html"><a href="more-about-random-walks.html"><i class="fa fa-check"></i><b>4</b> More about Random Walks</a><ul>
<li class="chapter" data-level="4.1" data-path="more-about-random-walks.html"><a href="more-about-random-walks.html#the-reflection-principle"><i class="fa fa-check"></i><b>4.1</b> The reflection principle</a></li>
<li class="chapter" data-level="4.2" data-path="more-about-random-walks.html"><a href="more-about-random-walks.html#stopping-times"><i class="fa fa-check"></i><b>4.2</b> Stopping times</a></li>
<li class="chapter" data-level="4.3" data-path="more-about-random-walks.html"><a href="more-about-random-walks.html#walds-formula-and-gamblers-ruin"><i class="fa fa-check"></i><b>4.3</b> Wald’s formula and Gambler’s ruin</a></li>
<li class="chapter" data-level="4.4" data-path="more-about-random-walks.html"><a href="more-about-random-walks.html#additional-problems-for-chapter-4"><i class="fa fa-check"></i><b>4.4</b> Additional problems for Chapter 4</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="dist.html"><a href="dist.html"><i class="fa fa-check"></i><b>A</b> Probability Distributions</a><ul>
<li class="chapter" data-level="A.1" data-path="dist.html"><a href="dist.html#discrete-distributions"><i class="fa fa-check"></i><b>A.1</b> Discrete distributions:</a></li>
<li class="chapter" data-level="A.2" data-path="dist.html"><a href="dist.html#continuous-distributions"><i class="fa fa-check"></i><b>A.2</b> Continuous distributions:</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Lecture notes for "Introduction to Stochastic Processes"</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="more-about-random-walks" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> More about Random Walks</h1>
<div style="counter-reset: thechapter 4;">

</div>
<div id="the-reflection-principle" class="section level2">
<h2><span class="header-section-number">4.1</span> The reflection principle</h2>
<p>Counting trajectories in order to compute probabilities is a powerful method,
as our next example shows. It also reveals a potential
weakness of the combinatorial approach: it works best when all <span class="math inline">\(\omega\)</span>
are equally likely (i.e., when <span class="math inline">\(p=\tfrac{1}{2}\)</span> in the case of the random walk).</p>
<p>We start by asking a simple question; what is the typical record value
of the random walk, i.e., how far “up” (or “right” depending on your point of view)
does it typically get? Clearly,
the largest value it can attain is <span class="math inline">\(T\)</span>. This happens only when
all coin tosses came up <span class="math inline">\(+1\)</span>, an extremely unlikely event -
its probability is <span class="math inline">\(2^{-T}\)</span>. On the other hand, this maximal value is at least <span class="math inline">\(0\)</span>, since
<span class="math inline">\(X_0=0\)</span>, already. A bit of thought reveals that any value between those
two extremes is possible, but it is not at all easy to compute their
probabilities.</p>
<p>More precisely, if <span class="math inline">\(\{X_n\}\)</span> is a simple random walk with time horizon
<span class="math inline">\(T\)</span>. We define its <strong>running-maximum process</strong> <span class="math inline">\(\{M_n\}_{n\in {\mathbb{N}}_0}\)</span> by
<span class="math display">\[M_n=\max(X_0,\dots, X_n),\ \text{ for }0 \leq n \leq T,\]</span>
and ask what the probabilities <span class="math inline">\({\mathbb{P}}[M_n = k]\)</span> for <span class="math inline">\(k=0,\dots, n\)</span> are?
An easy numerical solution to this problem can given by simulation. We reuse the function
<code>simulate_walk</code> defined at the beginning of the chapter, but also employ a new function, called <code>apply</code> which “applies” a function to each row (or column) of a data frame or a matrix. It seems to be tailor-made for our purpose<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> because we want to compute the maximum of each row of the simulation matrix (remember - the row means keep the realization fixed, but vary the time-index <span class="math inline">\(n\)</span>). The syntax of <code>apply</code> is simple - it needs the data frame, the margin (rows are coded as 1 and columns as 2) and the function to be applied (<code>max</code> in our case). The output is a vector of size <code>nsim</code> with all row-wise maxima:</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="more-about-random-walks.html#cb129-1"></a>walk =<span class="st"> </span><span class="kw">simulate_walk</span>(<span class="dt">nsim =</span> <span class="dv">100000</span>, <span class="dt">T =</span> <span class="dv">12</span>, <span class="dt">p =</span> <span class="fl">0.5</span>)</span>
<span id="cb129-2"><a href="more-about-random-walks.html#cb129-2"></a>M =<span class="st"> </span><span class="kw">apply</span>(walk, <span class="dv">1</span>, max)</span>
<span id="cb129-3"><a href="more-about-random-walks.html#cb129-3"></a><span class="kw">hist</span>(M, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="fl">12.5</span>, <span class="dv">1</span>), <span class="dt">probability =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-167-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The overall shape of the distribution is as we expected; the support is <span class="math inline">\(\{0,1,2,\dots, 12\}\)</span> and the
probabilities tend to decrease as <span class="math inline">\(k\)</span> gets larger. The unexpected feature is that <span class="math inline">\({\mathbb{P}}[ M_{12} = 1]\)</span> seems
to be the same as <span class="math inline">\({\mathbb{P}}[ M_{12} = 2]\)</span>. It drops after that for <span class="math inline">\(k=3\)</span>, but it looks like
<span class="math inline">\({\mathbb{P}}[ M_{12} = 3] = {\mathbb{P}}[ M_{12}=4]\)</span> again. Somehow the probability does not seem to change at
all from <span class="math inline">\(2i-1\)</span> to <span class="math inline">\(2i\)</span>.</p>
<p>Fortunately, there is an explicit formula for the distribution of <span class="math inline">\(M_n\)</span> and we can derive it
by a nice counting trick known as <strong>the reflection principle</strong>.</p>
<p>As usual, we may assume without loss of generality that <span class="math inline">\(n=T\)</span> since the
values of <span class="math inline">\(\delta_{n+1}, \dots, \delta_T\)</span> do not affect <span class="math inline">\(M_n\)</span> at all.
We start by picking a level <span class="math inline">\(l\in\{1,\dots, n\}\)</span> and first compute
the probability <span class="math inline">\({\mathbb{P}}[M_n\geq l]\)</span> - it will turn out to be easier than
attacking <span class="math inline">\({\mathbb{P}}[ M_n=l]\)</span> directly. The symmetry assumption <span class="math inline">\(p=1/2\)</span> ensures that
all trajectories are equally likely, so we can do this by counting the
number of trajectories whose maximal level reached is at least <span class="math inline">\(l\)</span>, and
then multiply by <span class="math inline">\(2^{-n}\)</span>.</p>
<p>What makes the computation of <span class="math inline">\({\mathbb{P}}[M_n \geq l]\)</span> a bit easier than that
of <span class="math inline">\({\mathbb{P}}[ M_n = l]\)</span> is the following equivalence</p>
<p><span class="math display">\[M_n\geq l \text{ if and only if } X_k=l \text{ for some } k.\]</span></p>
<p>In words, the set of trajectories whose maximum is at least <span class="math inline">\(l\)</span> is
exactly the same as the set of trajectories that hit the level <span class="math inline">\(l\)</span> at
some time. Let us denote the set of trajectories <span class="math inline">\(\omega\)</span> with this property by
<span class="math inline">\(A_l\)</span>, so that <span class="math inline">\({\mathbb{P}}[ M_n \geq l] = {\mathbb{P}}[A_l]\)</span>.
We can further split <span class="math inline">\(A_l\)</span> into three disjoint events <span class="math inline">\(A_l^{&gt;}\)</span>,
<span class="math inline">\(A_l^{=}\)</span> and <span class="math inline">\(A_l^{&lt;}\)</span>, depending on whether <span class="math inline">\(X_n&lt;l\)</span>, <span class="math inline">\(X_n=l\)</span> or <span class="math inline">\(X_n&gt;l\)</span>.
In the picture below, the red trajectory is in <span class="math inline">\(A_l^{&gt;}\)</span>, the green trajectory in <span class="math inline">\(A_l^=\)</span>
the orange one in <span class="math inline">\(A_l^{&lt;}\)</span>, while the blue one is not in <span class="math inline">\(A_l\)</span> at all.</p>
<center>
<p><img src="_main_files/figure-html/unnamed-chunk-168-1.png" width="80%" style="display: block; margin: auto;" /></p>
</center>
<p>With the set of all trajectories <span class="math inline">\(\Omega\)</span> partitioned into four disjoint classes, namely <span class="math inline">\(A^&gt;_l, A^=_l, A^&lt;_l\)</span> and <span class="math inline">\((A_l)^c\)</span>, we are ready to reveal the main idea behind the reflection principle:</p>
<center style="margin-bottom: 20px;">
<span class="math inline">\(A_l^&lt;\)</span> and <span class="math inline">\(A_l^&gt;\)</span> have exactly the same number of elements, i.e., <span class="math inline">\(\# A^&gt;_l = \# A_l^&lt;\)</span>.
</center>
<p>To see why that is true, start by choosing a trajectory <span class="math inline">\(\omega\in A_l^{&gt;}\)</span> and denoting by
<span class="math inline">\(\tau_l(\omega)\)</span> the <em>first time</em> <span class="math inline">\(\omega\)</span> visits the
level <span class="math inline">\(l\)</span>. Since <span class="math inline">\(\omega \in A^&gt;\)</span> such a time clearly exists.
Then we associate to <span class="math inline">\(\omega\)</span> another trajectory, call it <span class="math inline">\(\bar{\omega}\)</span>, obtained from <span class="math inline">\(\omega\)</span>
in the following way:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\bar{\omega}\)</span> and <span class="math inline">\(\omega\)</span> are the same until the time <span class="math inline">\(\tau_l(\omega)\)</span>.</li>
<li>After that, <span class="math inline">\(\bar{\omega}\)</span> is the reflection of <span class="math inline">\(\omega\)</span> around the level <span class="math inline">\(l\)</span>.</li>
</ol>
<p>Equivalently the increments of <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\bar{\omega}\)</span> are exactly the same up to time <span class="math inline">\(\tau(\omega)\)</span>, and exactly the opposite afterwards. In the picture below - the orange trajectory is <span class="math inline">\(\omega\)</span> and the green trajectory is its
“reflection” <span class="math inline">\(\bar{\omega}\)</span>; note that they overlap until time <span class="math inline">\(5\)</span>:</p>
<center>
<p><img src="_main_files/figure-html/unnamed-chunk-169-1.png" width="80%" style="display: block; margin: auto;" /></p>
</center>
<p>Convince yourself that this procedure establishes
a bijection between the sets <span class="math inline">\(A_l^{&gt;}\)</span> and <span class="math inline">\(A_l^{&lt;}\)</span>, making these two
sets equal in size.</p>
<p>So why is it important to know that <span class="math inline">\(\# A_l^&gt; = \# A_l^&lt;\)</span>? Because the trajectories in
<span class="math inline">\(A_l^&gt;\)</span> (as well as in <span class="math inline">\(A_l^=\)</span>) are easy to count.
For them, the requirement that the level
<span class="math inline">\(l\)</span> is hit at a certain point is redundant; if you are at or above <span class="math inline">\(l\)</span>
at the very end, you must have hit <span class="math inline">\(l\)</span> at a certain point.<br />
Therefore, <span class="math inline">\(A_l^{&gt;}\)</span> is simply the family of those trajectories
<span class="math inline">\(\omega\)</span> whose final positions <span class="math inline">\(X_n(\omega)\)</span> are somewhere strictly above <span class="math inline">\(l\)</span>. Hence,
<span class="math display">\[\begin{align}
       {\mathbb{P}}[A_l^{&gt;}] &amp;= {\mathbb{P}}[ X_n=l+1 \text{ or } X_n = l+2 \text{ or } \dots \text{ or }
     X_n=n]\\ &amp; = \sum_{k=l+1}^n {\mathbb{P}}[X_n = k]
\end{align}\]</span></p>
<p>Similarly, <span class="math display">\[\begin{aligned}
     {\mathbb{P}}[ A_l^{=}] = {\mathbb{P}}[X_n=l].\end{aligned}\]</span>
Finally, by the reflection principle,
<span class="math display">\[\begin{aligned}
    {\mathbb{P}}[ A_l^{&lt;}] = {\mathbb{P}}[A_l^{&gt;}] = \sum_{k=l+1}^n {\mathbb{P}}[X_n=k].\end{aligned}\]</span></p>
<p>Putting all of this
together, we get <span class="math display">\[\begin{aligned}
    {\mathbb{P}}[ A_l ] = {\mathbb{P}}[ X_n=l] + 2 \sum_{k=l+1}^n {\mathbb{P}}[X_n=k],\end{aligned}\]</span>
so that <span class="math display">\[\begin{aligned}
    {\mathbb{P}}[ M_n = l ] &amp;= {\mathbb{P}}[ M_n \geq l] - {\mathbb{P}}[ M_n \geq l+1]\\ &amp; = {\mathbb{P}}
    [A_l] - {\mathbb{P}}
    [A_{l+1}]\\ &amp; =
    {\mathbb{P}}[ X_n = l] + 2 {\mathbb{P}}[X_n = l+1] + 2{\mathbb{P}}[X_n = l+2]+ \dots + 2{\mathbb{P}}[ X_n=n] -\\
    &amp; \qquad \qquad  \quad \  -
    {\mathbb{P}}[ X_n = l+1] - 2 {\mathbb{P}}[X_n = l+2] - \dots - 2{\mathbb{P}}[ X_n=n]\\
    &amp;= {\mathbb{P}}[ X_n=l] + {\mathbb{P}}[X_n=l+1]
    \end{aligned}\]</span></p>
<p>Now that we have the explicit expression
<span class="math display">\[ {\mathbb{P}}[ M_n = l ] = {\mathbb{P}}[ X_n=l] + {\mathbb{P}}[X_n = l+1] \text{ for } l=0,1,\dots, n,\]</span>
we can shed some light on the fact on the shape of the histogram for <span class="math inline">\(M_n\)</span> we plotted above.
Since <span class="math inline">\({\mathbb{P}}[X_n=l]\)</span> is <span class="math inline">\(0\)</span> if <span class="math inline">\(n\)</span> and <span class="math inline">\(l\)</span> don’t have the same parity, it is clear that only
one of the probabilities <span class="math inline">\({\mathbb{P}}[X_n=l]\)</span> and <span class="math inline">\({\mathbb{P}}[X_n=l+1]\)</span> can be positive. It follows that, for
<span class="math inline">\(n\)</span> even, we have
<span class="math display">\[\begin{align}
{\mathbb{P}}[ M_n =0] &amp;= {\mathbb{P}}[X_n=0] + {\mathbb{P}}[X_n=1] = {\mathbb{P}}[X_n=0]\\
{\mathbb{P}}[M_n=1] &amp;= {\mathbb{P}}[ X_n=1] + {\mathbb{P}}[X_n=2] = {\mathbb{P}}[X_n=2]\\
{\mathbb{P}}[M_n=2] &amp;= {\mathbb{P}}[ X_n=2] + {\mathbb{P}}[X_n=3] = {\mathbb{P}}[X_n=2]\\
{\mathbb{P}}[M_n=3] &amp;= {\mathbb{P}}[ X_n=3] + {\mathbb{P}}[X_n=4] = {\mathbb{P}}[X_n=4]\\
{\mathbb{P}}[M_n=4] &amp;= {\mathbb{P}}[ X_n=4] + {\mathbb{P}}[X_n=5] = {\mathbb{P}}[X_n=4] \text{ etc.}
\end{align}\]</span>
In a similar way, for <span class="math inline">\(n\)</span> odd, we have
<span class="math display">\[\begin{align}
{\mathbb{P}}[ M_n =0] &amp;= {\mathbb{P}}[X_n=0] + {\mathbb{P}}[X_n=1] = {\mathbb{P}}[X_n=1]\\
{\mathbb{P}}[M_n=1] &amp;= {\mathbb{P}}[ X_n=1] + {\mathbb{P}}[X_n=2] = {\mathbb{P}}[X_n=1]\\
{\mathbb{P}}[M_n=2] &amp;= {\mathbb{P}}[ X_n=2] + {\mathbb{P}}[X_n=3] = {\mathbb{P}}[X_n=3]\\
{\mathbb{P}}[M_n=3] &amp;= {\mathbb{P}}[ X_n=3] + {\mathbb{P}}[X_n=4] = {\mathbb{P}}[X_n=3]\\
{\mathbb{P}}[M_n=4] &amp;= {\mathbb{P}}[ X_n=4] + {\mathbb{P}}[X_n=5] = {\mathbb{P}}[X_n=5] \text{ etc.}
\end{align}\]</span></p>
<p>Here is a example of a typical problem where the reflection principle (i.e., the formula for <span class="math inline">\({\mathbb{P}}[M_n=k]\)</span>) is used:</p>
<div class="problem">
<p>Let <span class="math inline">\(X\)</span> be a simple symmetric random walk.
What is the probability that <span class="math inline">\(X_n\leq 0\)</span> for all <span class="math inline">\(0\leq n \leq T\)</span>?</p>
</div>
<div class="solution">
<p>This is really a question about the maximum, but in disguise. The walk will stay negative or <span class="math inline">\(0\)</span> if and only if its
its running maximum <span class="math inline">\(M_T\)</span> at time <span class="math inline">\(T\)</span> takes the value <span class="math inline">\(0\)</span>. By our formula for <span class="math inline">\({\mathbb{P}}[M_n=l]\)</span> we have
<span class="math display">\[ {\mathbb{P}}[M_T=0] = {\mathbb{P}}[X_T=0] + {\mathbb{P}}[X_T = 1].\]</span>
When <span class="math inline">\(T=2N\)</span> is even this evaluates to <span class="math inline">\(\binom{2N}{N} 2^{-2N}\)</span>, and when <span class="math inline">\(T=2N-1\)</span> to
<span class="math inline">\(\binom{2N-1}{N} 2^{-(2N-1)}\)</span>.</p>
</div>
<div class="problem">
<p>What is the probability that a simple symmetric random walk will reach the level <span class="math inline">\(l=1\)</span> in <span class="math inline">\(T\)</span> steps or fewer?
What happens when <span class="math inline">\(T\to\infty\)</span>?</p>
</div>
<div class="solution">
<p>The first question is exactly the opposite of the question in our previous example, so the answer is
<span class="math display">\[ 1 - {\mathbb{P}}[M_T=0] = 1- {\mathbb{P}}[X_T=0] - {\mathbb{P}}[X_T=1].\]</span>
As above, this evaluates to <span class="math inline">\(\binom{2N}{N} 2^{-2N}\)</span> when <span class="math inline">\(T=2N\)</span> is even (we skip the case of odd <span class="math inline">\(T\)</span> because it is very similar).
When <span class="math inline">\(N\to\infty\)</span>, we expect <span class="math inline">\(\binom{2N}{N}\)</span> to go to <span class="math inline">\(+\infty\)</span> and <span class="math inline">\(2^{-2N}\)</span> to go to
<span class="math inline">\(0\)</span>, so it is not immediately clear which term will win.
One way to make a guess is to think about it probabilistically: we are looking at the
probability <span class="math inline">\({\mathbb{P}}[X_{2N}=0]\)</span> that the random walk takes the
value <span class="math inline">\(0\)</span> after exactly <span class="math inline">\(2N\)</span> steps. Even though no other (single) value is more
likely to happen, there are so many other values <span class="math inline">\(X_{2N}\)</span> could take (anything
from <span class="math inline">\(-2N\)</span> to <span class="math inline">\(2N\)</span> except for <span class="math inline">\(0\)</span>) that we conjecture that
its probability converges to <span class="math inline">\(0\)</span>. A formal mathematical argument which proves that
our conjecture is, indeed correct, involves <strong>Stirling’s formula</strong>:</p>
<p><span class="math display">\[ N! \sim \sqrt{2 \pi N} \left( \frac{N}{e} \right)^N \text{ where }
   A_N \sim B_N \text{ means that } \lim_{N\to\infty} \frac{A_N}{B_N}=1. \]</span></p>
<p>We write <span class="math inline">\(\binom{2N}{N} = \tfrac{(2N)!}{N! N!}\)</span> and apply Stirling’s formula to each factorial (let’s skip the details)
to conclude that
<span class="math display">\[ 
  \binom{2N}{N} 2^{-2n}\sim \frac{1}{\sqrt{N \pi}} 
  \text{ so that }  \lim_{N\to\infty}
  \binom{2N}{N} 2^{-2n}
  = 0 \]</span></p>
</div>
<p>The result of the previous problem implies the following important fact:</p>
<blockquote>
<p>The simple symmetric random walk will reach the level <span class="math inline">\(1\)</span>,
with certainty, given enough time.</p>
</blockquote>
<p>Indeed, we just proved that the probability of this not happening during the first <span class="math inline">\(T\)</span> steps
shrinks down to <span class="math inline">\(0\)</span> as <span class="math inline">\(T\to\infty\)</span>.</p>
<p>But wait, there is more! By symmetry, the level <span class="math inline">\(1\)</span> can be replaced by <span class="math inline">\(-1\)</span>. Also, once we hit
<span class="math inline">\(1\)</span>, the random walk “renews itself” (this property is called the Strong
Markov Property and we will talk about it later), so it will eventually
hit the level <span class="math inline">\(2\)</span>, as well. Continuing the same way, we get the
following remarkable result</p>
<blockquote>
<p><strong>Sooner or later, the symple symmetric random walk will visit any level.</strong></p>
</blockquote>
<p>We close this chapter with an application of the reflection principle
to a classical problem in probability and combinatorics. Feel free to skip it
if you want to.</p>
<div class="problemec">
<p>Suppose that two
candidates, Daisy and Oscar, are running for office, and <span class="math inline">\(T \in{\mathbb{N}}\)</span>
voters cast their ballots. Votes are counted the old-fashioned way,
namely by the same official, one by one, until all <span class="math inline">\(T\)</span> of them have been
processed. After each ballot is opened, the official records the number
of votes each candidate has received so far. At the end, the official
announces that Daisy has won by a margin of <span class="math inline">\(k&gt;0\)</span> votes, i.e., that
Daisy got <span class="math inline">\((T+k)/2\)</span> votes and Oscar the remaining <span class="math inline">\((T-k)/2\)</span> votes. What
is the probability that at no time during the counting has Oscar been in
the lead?</p>
</div>
<div class="solution">
<p>We assume that the order in which the official counts the votes is
completely independent of the actual votes, and that each voter chooses
Daisy with probability <span class="math inline">\(p\in (0,1)\)</span> and Oscar with probability <span class="math inline">\(q=1-p\)</span>.
We don’t know a-priori what <span class="math inline">\(p\)</span> is, and, as it turns out, we don’t need to!</p>
<p>For <span class="math inline">\(0 \leq n \leq T\)</span>, let <span class="math inline">\(X_n\)</span> be the number of votes received by
Daisy <em>minus</em> the number of votes received by Oscar in the first <span class="math inline">\(n\)</span>
ballots. When the <span class="math inline">\(n+1\)</span>-st vote is counted, <span class="math inline">\(X_n\)</span> either increases by
<span class="math inline">\(1\)</span> (if the vote was for Daisy), or decreases by 1 otherwise. The votes
are independent of each other and <span class="math inline">\(X_0=0\)</span>, so <span class="math inline">\(X_n\)</span>, <span class="math inline">\(0\leq n \leq T\)</span> is
a simple random walk with the time horizon <span class="math inline">\(T\)</span>. The probability of an
up-step is <span class="math inline">\(p\in (0,1)\)</span>, so this random walk is not necessarily
symmetric. The ballot problem can now be restated as follows:</p>
<p><em>For a simple random walk <span class="math inline">\(\{X_n\}_{0\leq n \leq T}\)</span>, what is the
probability that <span class="math inline">\(X_n\geq 0\)</span> <strong>for all</strong> <span class="math inline">\(n\)</span> with <span class="math inline">\(0\leq n \leq T\)</span>, given that
<span class="math inline">\(X_T=k\)</span>?</em></p>
<p>The first step towards understanding the solution is the realization
that the exact value of <span class="math inline">\(p\)</span> does not matter. Indeed, we are interested
in the conditional probability <span class="math inline">\({\mathbb{P}}[ F|G]={\mathbb{P}}[F\cap G]/{\mathbb{P}}[G]\)</span>, where
<span class="math inline">\(F\)</span> denotes the set of <span class="math inline">\(\omega\)</span> whose corresponding trajectories always
stay non-negative, while the trajectories corresponding to <span class="math inline">\(\omega\in G\)</span>
reach <span class="math inline">\(k\)</span> at time <span class="math inline">\(n\)</span>. Each <span class="math inline">\(\omega \in G\)</span> consists of exactly <span class="math inline">\((T+k)/2\)</span>
up-steps (<span class="math inline">\(1\)</span>s) and <span class="math inline">\((T-k)/2\)</span> down steps (<span class="math inline">\(-1\)</span>s), so its probability
weight is equal to <span class="math inline">\(p^{ (T+k)/2} q^{(T-k)/2}\)</span>. Therefore, with <span class="math inline">\(\# A\)</span>
denoting the number of elements in the set <span class="math inline">\(A\)</span>, we get <span class="math display">\[\begin{aligned}
 {\mathbb{P}}[ F|G]=\frac{{\mathbb{P}}[F\cap G]}{{\mathbb{P}}[G]}=\frac{\# (F\cap G) \ p^{
    (T+k)/2} q^{(T-k)/2}}{ \# G \ p^{ (T+k)/2}
  q^{(T-k)/2}}=\frac{\#(F\cap G)}{\# G}.\end{aligned}\]</span> This is quite
amazing in and of itself. This conditional probability does not depend
on <span class="math inline">\(p\)</span> at all!</p>
<p>Since we already know how to count the number of elements in <span class="math inline">\(G\)</span> (there
are <span class="math inline">\(\binom{T}{(T+k)/2}\)</span>), “all” that remains to be done is to count the
number of elements in <span class="math inline">\(G\cap F\)</span>. The elements in <span class="math inline">\(G \cap F\)</span> form a
portion of all the elements in <span class="math inline">\(G\)</span> whose trajectories don’t hit the
level <span class="math inline">\(l=-1\)</span>; this way, <span class="math inline">\(\#(G\cap F)=\#G-\#H\)</span>, where <span class="math inline">\(H\)</span> is the set of
all paths which finish at <span class="math inline">\(k\)</span>, but cross (or, at least, touch) the level
<span class="math inline">\(l=-1\)</span> in the process. Can we use the reflection principle to find
<span class="math inline">\(\# H\)</span>? Yes, we can. In fact, you can convince yourself that the
reflection of any trajectory corresponding to <span class="math inline">\(\omega \in H\)</span> around the
level <span class="math inline">\(l=-1\)</span> after its last hitting time of that level produces a
trajectory that starts at <span class="math inline">\(0\)</span> and ends at <span class="math inline">\(-k-2\)</span>, and vice versa. The
number of paths from <span class="math inline">\(0\)</span> to <span class="math inline">\(-k-2\)</span> is easy to count - it is equal to
<span class="math inline">\(\binom{T}{(T+k)/2+1}\)</span>. Putting everything together, we get
<span class="math display">\[{\mathbb{P}}[ F|G]=\frac{\binom{T}{n_1}-\binom{T}{n_1+1}}
{\binom{T}{n_1}}=\frac{k+1}{n_1+1},\text{ where }n_1=\frac{T+k}{2}.\]</span>
The last equality follows from the definition of binomial coefficients
<span class="math inline">\(\binom{T}{i}=\frac{T!}{i!(T-i)!}\)</span>.</p>
<p>The Ballot problem has a long history (going back to at least 1887) and
has spurred a lot of research in combinatorics and probability. In fact,
people still write research papers on some of its generalizations. When
posed outside the context of probability, it is often phrased as “<em>in
how many ways can the counting be performed …</em>” (the difference being
only in the normalizing factor <span class="math inline">\(\binom{T}{n_1}\)</span> appearing in Example
above). A special case <span class="math inline">\(k=0\)</span> seems to be even
more popular - the number of <span class="math inline">\(2n\)</span>-step paths from <span class="math inline">\(0\)</span> to <span class="math inline">\(0\)</span> never going
below zero is called the <strong><span class="math inline">\(n\)</span>-th Catalan number</strong> and equals
<span class="math display">\[\begin{align}
   C_n=\frac{1}{n+1} \binom{2n}{n}.
 \end{align}\]</span></p>
</div>
</div>
<div id="stopping-times" class="section level2">
<h2><span class="header-section-number">4.2</span> Stopping times</h2>
<p>COMING SOON</p>
</div>
<div id="walds-formula-and-gamblers-ruin" class="section level2">
<h2><span class="header-section-number">4.3</span> Wald’s formula and Gambler’s ruin</h2>
<p>COMING SOON</p>
</div>
<div id="additional-problems-for-chapter-4" class="section level2">
<h2><span class="header-section-number">4.4</span> Additional problems for Chapter 4</h2>
<!--
  3-max-problems
  ------------------------------------------------
-->
<div class="problem">
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(\{X_n\}_{0\leq n \leq 10}\)</span> be a simple symmetric random walk with
time horizon <span class="math inline">\(T=10\)</span>. What is the probability it will never reach the
level <span class="math inline">\(5\)</span>?</p></li>
<li><p>A fair coin is tossed repeatedly, with the first toss resulting in <span class="math inline">\(H\)</span>
(i.e., heads). After that, each time the outcome of the coin matches the
previous outcome, the player gets a dollar. If the two do not match, the
player has to pay a dollar. The player stops playing once she “earns”
<span class="math inline">\(10\)</span> dollars. What is the probability that she will need at least 20
tosses (including the first one) to achieve that?</p></li>
<li><p>A fair coin is tossed repeatedly and the record of the outcomes is kept.
Tossing stops the moment the total number of heads obtained so far
exceeds the total number of tails by 3. For example, a possible sequence
of tosses could look like <em>HHTTTHHTHHTHH</em>. What is the probability that
the length of such a sequence is at most 10?</p></li>
</ol>
</div>
<!-- <div class="solution"> -->
<!-- ```{r child="problems/01_Random_Walks/3-max-problems_sol.Rmd"} -->
<!-- ``` -->
<!-- </div> -->
<!--
  time_until_hit
  ------------------------------------------------
-->
<div class="problem">
<p>The purpose of this problem is to understand how long we have to wait util a simple symmetric random walk hits the level <span class="math inline">\(1\)</span>. Theory presented so far guarantees that this will happen sooner or later, but it gives no indication of the length of the wait. As usual, we denote by <span class="math inline">\(\tau_1\)</span> the (random) first time the SSRW <span class="math inline">\(\{X_n\}_{n\in{\mathbb{N}}_0}\)</span> hits the level <span class="math inline">\(1\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Write an R function that simulates a trajectory of a random walk, but only until the first time it hits level <span class="math inline">\(1\)</span>. You don’t have to record the trajectory itself - just keep tossing coins until the trajectory hits <span class="math inline">\(1\)</span> and return the number of steps needed. Your function needs to accept an argument, <code>T</code>, such that your simulation stops if <span class="math inline">\(1\)</span> has not been reached in the first <code>T</code> steps.</p></li>
<li><p>Pick a large-ish value of the parameter <code>T</code> (say <span class="math inline">\(100\)</span>) and <code>replicate</code> the simulation from 1. above sufficiently many times (say <span class="math inline">\(10,000\)</span>). Draw a histogram of your results.</p></li>
<li><p>Repeat the simulation for the following values of <span class="math inline">\(T\)</span>: <span class="math inline">\(500\)</span>, <span class="math inline">\(1,000\)</span>, <span class="math inline">\(10,000\)</span>, <span class="math inline">\(50,000\)</span>, <span class="math inline">\(100,000\)</span>, and compute the mean and the standard deviation of your simulations. Display your results in two tables. Are these numbers underestimates or overestimates of <span class="math inline">\({\mathbb{E}}[\tau_1]\)</span> and <span class="math inline">\(\operatorname{Var}[\tau_1]\)</span>? Explain why. (Note: Decrease the number <code>nsim</code> of simulations to <span class="math inline">\(1000\)</span> or even <span class="math inline">\(100\)</span> if <span class="math inline">\(10,000\)</span> is taking too long.)</p></li>
<li><p>Repeat all of the above, but for the first time the <strong>absolute value</strong> of your random walk reaches level <span class="math inline">\(5\)</span>. What is the most glaring difference between the two cases? What does that mean for the amount of time you are going to have to wait to hit <span class="math inline">\(1\)</span>, vs. for the absolute value to hit <span class="math inline">\(5\)</span>? More precisely, what do you think their means and standard deviations are?</p></li>
</ol>
</div>
<!-- <div class="solution"> -->
<!-- ```{r child="problems/01_Random_Walks/time_until_hit_sol.Rmd"} -->
<!-- ``` -->
<!-- </div> -->
<!-- 
  Luke_cookies
  -------------------------------
-->
<div class="problem">
<p>Luke starts a random walk, where each step takes him to the left or to
the right, with the two alternatives being equally likely and
independent of the previous steps. <span class="math inline">\(11\)</span> steps to his right is a cookie
jar, and Luke gets to take a (single) cookie every time he reaches that
position. He performs exactly <span class="math inline">\(15\)</span> steps, and then stops.</p>
<ol style="list-style-type: decimal">
<li><p>What is the probability that Luke will be exactly by the cookie jar
when he stops?</p></li>
<li><p>What is the probability that Luke stops with with exactly <span class="math inline">\(3\)</span>
cookies in his hand?</p></li>
<li><p>What is the probability that Luke stops with at least one cookie in
his hand?</p></li>
<li><p>Suppose now that we place a bowl of broccoli soup one step to the
right of the cookie jar. It smells so bad that, if reached, Luke
will throw away all the cookies he is currently carrying (if any)
and run away pinching his nose. What is the probability that Luke
will finish his <span class="math inline">\(15\)</span>-step walk without ever encountering the yucky
bowl of broccoli soup and with at least one cookie in his hand?</p></li>
</ol>
</div>
<!-- <div class="solution"> -->
<!-- ```{r child="problems/01_Random_Walks/Luke_cookies_sol.Rmd"} -->
<!-- ``` -->
<!-- </div> -->
<!--
  catalan
  ------------------------------------------------
-->
<div class="problemec">
<p>Let <span class="math inline">\(C_n = \frac{1}{n+1}\binom{2n}{n}\)</span> denote the <span class="math inline">\(n\)</span>-th Catalan number, as defined at the end of the discussion of the Balot problem above.</p>
<ol style="list-style-type: decimal">
<li><p>Use the reflection principle to show that <span class="math inline">\(C_n\)</span> is the number
trajectories <span class="math inline">\((x_0,\dots, x_{2n})\)</span> of a random
walk with time horizon <span class="math inline">\(T=2n\)</span> such that <span class="math inline">\(x_k  \geq 0\)</span>, for all <span class="math inline">\(k\in\{0,1,\dots, 2n\}\)</span> and <span class="math inline">\(x_{2n}=0\)</span>.</p></li>
<li><p>Prove the <em>Segner’s recurrence formula</em>
<span class="math inline">\(C_{n+1} = \sum_{i=0}^n C_{i} C_{n-i}\)</span>. .</p></li>
<li><p>Show that <span class="math inline">\(C_n\)</span> is the number of ways the vertices of a regular
<span class="math inline">\(2n\)</span>-gon can be paired so that the line segments joining paired
vertices do not intersect.</p></li>
<li><p>Prove that <span class="math display">\[C_n = \binom{2n}{n} - \binom{2n}{n+1},\]</span> both
algebraically (using the formula for the binomial coefficient) and
combinatorially (by counting).</p></li>
</ol>
</div>
<!-- <div class="solution"> -->
<!-- ```{r child="problems/01_Random_Walks/catalan_sol.Rmd"} -->
<!-- ``` -->
<!-- </div> -->
<p>⬇︎ In case you were wondering, the text below belongs to footnotes from somewhere high above.⬇︎</p>


</div>
</div>



<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p>the function <code>apply</code> is often used as a substitute for a <code>for</code> loop because it has several advantages over it. First, the code is much easier to read and understand. Second, <code>apply</code> can easily be parallelized. Third, while this is not such a big issue anymore, <code>for</code> loops used to be orders of magnitude slower than the corresponding <code>apply</code> in the past. R’s <code>for</code> loops got much better recently, but they still lag behind <code>apply</code> in some cases. To be fair, <code>apply</code> is know to use more <em>memory</em> than <code>for</code> in certain cases.<a href="more-about-random-walks.html#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="random-walks.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dist.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": false,
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"search": true,
"toc_depth": null
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
