<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Classification of States | _main.utf8</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Classification of States | _main.utf8" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Classification of States | _main.utf8" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  


<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">M362M Lecture notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="06-Classification.html"><a href="#classification-of-states"><i class="fa fa-check"></i><b>1</b> Classification of States</a><ul>
<li class="chapter" data-level="1.1" data-path="06-Classification.html"><a href="#the-communication-relation"><i class="fa fa-check"></i><b>1.1</b> The Communication Relation</a></li>
<li class="chapter" data-level="1.2" data-path="06-Classification.html"><a href="#classes"><i class="fa fa-check"></i><b>1.2</b> Classes</a></li>
<li class="chapter" data-level="1.3" data-path="06-Classification.html"><a href="#transience-and-recurrence"><i class="fa fa-check"></i><b>1.3</b> Transience and recurrence</a><ul>
<li class="chapter" data-level="1.3.1" data-path="06-Classification.html"><a href="#the-return-theorem"><i class="fa fa-check"></i><b>1.3.1</b> The Return Theorem</a></li>
<li class="chapter" data-level="1.3.2" data-path="06-Classification.html"><a href="#a-recurrence-criterion"><i class="fa fa-check"></i><b>1.3.2</b> A recurrence criterion</a></li>
<li class="chapter" data-level="1.3.3" data-path="06-Classification.html"><a href="#polyas-theorem"><i class="fa fa-check"></i><b>1.3.3</b> Polya’s theorem</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="06-Classification.html"><a href="#class-properties"><i class="fa fa-check"></i><b>1.4</b> Class properties</a></li>
<li class="chapter" data-level="1.5" data-path="06-Classification.html"><a href="#a-few-examples"><i class="fa fa-check"></i><b>1.5</b> A few Examples</a></li>
<li class="chapter" data-level="1.6" data-path="06-Classification.html"><a href="#additional-problems-for-chapter-6"><i class="fa fa-check"></i><b>1.6</b> Additional problems for Chapter 6</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:title:end-->
<!--bookdown:title:start-->
<div id="classification-of-states" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Classification of States</h1>
<div style="counter-reset: thechapter 6;">

</div>
<p>There will be a lot of definitions and some theory before we get to
examples. You might want to peek ahead as notions are being introduced;
it will help your understanding.</p>
<div id="the-communication-relation" class="section level2">
<h2><span class="header-section-number">1.1</span> The Communication Relation</h2>
<p>Let <span class="math inline">\(\{X_n\}_{n\in {\mathbb{N}}_0}\)</span> be a Markov chain on the state space <span class="math inline">\(S\)</span>. For a given set
<span class="math inline">\(B\)</span> of states, define the <strong>(first) hitting time <span class="math inline">\(\tau_B\)</span></strong> (or <span class="math inline">\(\tau(B)\)</span> if subscripts are
impractical) <strong>of the set <span class="math inline">\(B\)</span></strong> as
<span class="math display">\[\begin{equation}
   \tau_B=\min \{ n\in{\mathbb{N}}_0\, : \, X_n\in B\}.
\end{equation}\]</span>
We know that <span class="math inline">\(\tau_B\)</span> is, in fact, a stopping time with
respect to <span class="math inline">\(\{X_n\}_{n\in {\mathbb{N}}_0}\)</span>. When <span class="math inline">\(B\)</span> consists of only one element
, e.g. <span class="math inline">\(B=\{i\}\)</span>, we simply write <span class="math inline">\(\tau_{i}\)</span> for <span class="math inline">\(\tau_{\{i\}}\)</span>; <span class="math inline">\(\tau_{i}\)</span>
is the first time the Markov chain <span class="math inline">\(\{X_n\}_{n\in {\mathbb{N}}_0}\)</span> “hits” the state <span class="math inline">\(i\)</span>. As
always, we allow <span class="math inline">\(\tau_{B}\)</span> to take the value <span class="math inline">\(\infty\)</span>; it means that
no state in <span class="math inline">\(B\)</span> is ever hit.</p>
<p>The hitting times are important both for applications, and for better
understanding of the structure of Markov chains in general.
For example, let <span class="math inline">\(\{X_n\}_{n\in {\mathbb{N}}_0}\)</span> be the chain which models a game of tennis (from the
previous lecture). The probability of winning for Player 1 can be
phrased in terms of hitting times: <span class="math display">\[{\mathbb{P}}[ \text{Player 1 wins}]={\mathbb{P}}[ 
\tau_{i_{1}}&lt;\tau_{i_{2}}],\]</span> where <span class="math inline">\(i_{1}=\)</span> “Player 1 wins” and <span class="math inline">\(i_{2}=\)</span>“Player 2
wins” (the two absorbing states of the chain). We will learn how to
compute such probabilities in the subsequent lectures.</p>
<p>Having introduced the hitting times <span class="math inline">\(\tau_B\)</span>, let us give a few more
definitions. It will be very convenient to consider the same Markov
chain with different initial distributions. Most often, these
distributions will correspond to starting from a fixed state (as opposed
to choosing the initial state at random). We use the notation <span class="math inline">\({\mathbb{P}}_i[A]\)</span>
to mean <span class="math inline">\({\mathbb{P}}[A|X_0=i]\)</span> (for any event <span class="math inline">\(A\)</span>), and <span class="math inline">\({\mathbb{E}}_i[A]={\mathbb{E}}[A|X_0=i]\)</span>
(for any random variable <span class="math inline">\(X\)</span>). In practice, we use <span class="math inline">\({\mathbb{P}}_i\)</span> and <span class="math inline">\({\mathbb{E}}_i\)</span>
to signify that we are starting the chain from the state <span class="math inline">\(i\)</span>, i.e.,
<span class="math inline">\({\mathbb{P}}_i\)</span> corresponds to a Markov chain whose transition matrix is the
same as the one of <span class="math inline">\(\{X_n\}_{n\in {\mathbb{N}}_0}\)</span>, but the initial distribution is given by
<span class="math inline">\({\mathbb{P}}_i[X_0=j]=0\)</span> if <span class="math inline">\(j\not = i\)</span> and <span class="math inline">\({\mathbb{P}}_i[X_0=i]=1\)</span>. Note also that
<span class="math inline">\({\mathbb{P}}_i[X_1=j] = p_{ij}\)</span> and that <span class="math inline">\({\mathbb{P}}_i[X_n=j] =p^{(n)}_{ij}\)</span>, for any <span class="math inline">\(n\)</span>.</p>
<p>A state <span class="math inline">\(i\in S\)</span> is said to <strong>communicate</strong> with the state <span class="math inline">\(j\in S\)</span>,
denoted by <span class="math inline">\(i\to j\)</span> if <span class="math display">\[{\mathbb{P}}_i[\tau_{j}&lt;\infty]&gt;0.\]</span></p>
<p>Intuitively, <span class="math inline">\(i\)</span> communicates with <span class="math inline">\(j\)</span> if there is a non-zero chance
that the Markov chain <span class="math inline">\(X\)</span> will eventually visit <span class="math inline">\(j\)</span> if it starts from
<span class="math inline">\(i\)</span>. Sometimes we also say that <span class="math inline">\(j\)</span> is <strong>a consequent of</strong> <span class="math inline">\(i\)</span>, that <span class="math inline">\(j\)</span>
<strong>is accessible from</strong> <span class="math inline">\(i\)</span>, or that <span class="math inline">\(j\)</span> <strong>follows</strong> <span class="math inline">\(i\)</span>.</p>
<p>In the “tennis” example of the previous chapter,
every state is accessible from <span class="math inline">\((0,0)\)</span> (the fact
that <span class="math inline">\(p\in (0,1)\)</span> is important here), but <span class="math inline">\((0,0)\)</span> is not accessible from
any other state. The consequents of <span class="math inline">\((0,0)\)</span> are not only <span class="math inline">\((15,0)\)</span> and
<span class="math inline">\((0,15)\)</span>, but also <span class="math inline">\((30,15)\)</span> or <span class="math inline">\((40,40)\)</span>. In fact, all states
are consequents of <span class="math inline">\((0,0)\)</span>. The consequents of <span class="math inline">\((40,40)\)</span> are <span class="math inline">\((40,40)\)</span> itself, <span class="math inline">\((40,Adv)\)</span>,
<span class="math inline">\((Adv, 40)\)</span>, “P1 wins” and “P2 wins”.</p>
<div class="problem">
<p>Explain why
<span class="math inline">\(i \to j\)</span> if and only if <span class="math inline">\(p^{(n)}_{ij}&gt;0\)</span> for some <span class="math inline">\(n\in{\mathbb{N}}_0\)</span>.</p>
</div>
<div class="solution">
<p>Leaving a rigorous mathematical proof aside, we note that the statement
is intuitively easy to understand. If <span class="math inline">\(i\to j\)</span> then there must exist
some time <span class="math inline">\(n\)</span> such that <span class="math inline">\({\mathbb{P}}_i[\tau_j = n]&gt;0\)</span>. This, in turn, implies
that it is possible to go from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span> in exactly <span class="math inline">\(n\)</span> steps, where
“possible” means “with positive probability”. In our notation, that is
exactly what <span class="math inline">\(p^{(n)}_{ij}&gt;0\)</span> means.</p>
<p>Conversely, if <span class="math inline">\(p^{(n)}_{ij}&gt;0\)</span> then
<span class="math inline">\({\mathbb{P}}_i[ \tau_j &lt;\infty] \geq {\mathbb{P}}_i[\tau_j \leq n] \geq {\mathbb{P}}_i[ X_n = j]=p^{(n)}_{ij}&gt;0.\)</span></p>
</div>
<p>Two immediate properties of the relation <span class="math inline">\(\to\)</span> are listed in the problem below:</p>
<div class="problem">
<p>Explain why the following statements are true for all states <span class="math inline">\(i,j,k\)</span> of a Markov chain.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(i\to i\)</span>,</p></li>
<li><p><span class="math inline">\(i\to j, j\to k\)</span> implies <span class="math inline">\(i \to k\)</span>.</p></li>
</ol>
</div>
<div class="solution">
<ol style="list-style-type: decimal">
<li><p>If we start from state <span class="math inline">\(i\in S\)</span> we are already there! More rigorously, note that <span class="math inline">\(0\)</span>
is allowed as a value for <span class="math inline">\(\tau_{B}\)</span> in its definition above, i.e., <span class="math inline">\(\tau_i=0\)</span> when <span class="math inline">\(X_0=i\)</span>.</p></li>
<li><p>Intuitively, if you can follow a path (sequence of arrows) from <span class="math inline">\(i\)</span> to <span class="math inline">\(j\)</span>, and then another path <span class="math inline">\(j\)</span> to <span class="math inline">\(k\)</span>,
you can do the same from <span class="math inline">\(i\)</span> to <span class="math inline">\(k\)</span> by concatenating two paths. More rigorously, by the previous problem,
it will be enough to show that <span class="math inline">\(p^{(n)}_{ik}&gt;0\)</span> for some <span class="math inline">\(n\in{\mathbb{N}}\)</span>. By the same
Proposition, we know that <span class="math inline">\(p^{(n_1)}_{ij}&gt;0\)</span> and <span class="math inline">\(p^{(n_2)}_{jk}&gt;0\)</span>
for some <span class="math inline">\(n_1,n_2\in{\mathbb{N}}_0\)</span>. By the Chapman-Kolmogorov relations, with
<span class="math inline">\(n=n_1+n_2\)</span>, we have
<span class="math display">\[\begin{equation}
  p^{(n)}_{ik} =\sum_{l\in S} p^{(n_1)}_{il} p^{(n_2)}_{lk}\geq  
  p^{(n_1)}_{ij} p^{(n_2)}_{jk}&gt;0.
\end{equation}\]</span>
Note that the inequality <span class="math inline">\(p^{(n)}_{ik}\geq p^{(n_1)}_{il}p^{(n_2)}_{lk}\)</span> is valid for
all <span class="math inline">\(i,l,k\in S\)</span>, as long as <span class="math inline">\(n_1+n_2=n\)</span>. It will come in handy later.</p></li>
</ol>
</div>
<p>Remember that the <strong>greatest common divisor (gcd)</strong> of a set <span class="math inline">\(A\)</span> of
natural numbers if the largest number <span class="math inline">\(d\in{\mathbb{N}}\)</span> such that <span class="math inline">\(d\)</span> divides
each <span class="math inline">\(k\in A\)</span>, i.e., such that each <span class="math inline">\(k\in A\)</span> is of the form <span class="math inline">\(k=l d\)</span> for
some <span class="math inline">\(l\in{\mathbb{N}}\)</span>.</p>
<p>A <strong>period</strong> <span class="math inline">\(d(i)\)</span> of a state <span class="math inline">\(i\in S\)</span> is the greatest common
divisor of the <strong>return set</strong> <span class="math display">\[R(i)= \{ n\in{\mathbb{N}}\, : \,  p^{(n)}_{ii}&gt;0\}\]</span>
of the state <span class="math inline">\(i\)</span>. When <span class="math inline">\(R(i)=\emptyset\)</span>, we set <span class="math inline">\(d(i)=1\)</span>. A state
<span class="math inline">\(i\in S\)</span> is called <strong>aperiodic</strong> if <span class="math inline">\(d(i)=1\)</span>.</p>
<div class="problem">
<p>Consider two Markov chains with three states and the transition matrices
<span class="math display">\[P_1=\begin{bmatrix}
 0 &amp; 1 &amp; 0 \\
 0 &amp; 0 &amp; 1 \\
 1 &amp; 0 &amp; 0 
\end{bmatrix}, \quad
P_2=\begin{bmatrix}
 0 &amp; 1 &amp; 0 \\
 0 &amp; 0 &amp; 1 \\
 \tfrac{1}{2} &amp; 0 &amp; \tfrac{1}{2} 
\end{bmatrix}\]</span></p>
<p>Find return sets and periods of each state <span class="math inline">\(i\)</span> of each chain.</p>
</div>
<div class="solution">
<p>For the first chain, with transition graph</p>
<p><img src="_main_files/figure-html/unnamed-chunk-3-1.png" width="672" style="margin-top:-10%; margin-bottom: -10%" style="display: block; margin: auto;" /></p>
<p>the return set for each state <span class="math inline">\(i\in\{1,2,3\}\)</span> is
given by <span class="math inline">\(R(i)= \{3,6,9,12,\dots\}\)</span>, so <span class="math inline">\(d(i)=3\)</span> for all
<span class="math inline">\(i\in\{1,2,3\}\)</span>.</p>
<p>Even though the transition graph of the second chain looks very similar to the first one</p>
<p><img src="_main_files/figure-html/unnamed-chunk-4-1.png" width="672" style="margin-top:-10%; margin-bottom: -10%" style="display: block; margin: auto;" /></p>
<p>the situation changes drastically:
<span class="math display">\[\begin{align}
  R(1) &amp; =\{ 3,4,5,6, \dots \},\\
  R(2) &amp; =\{ 2,3,4,5,6, \dots \},\\
  R(3) &amp; =\{ 1,2,3,4,5,6, \dots \},
\end{align}\]</span>
so that <span class="math inline">\(d(i)=1\)</span> for <span class="math inline">\(i\in\{1,2,3\}\)</span>.</p>
</div>
</div>
<div id="classes" class="section level2">
<h2><span class="header-section-number">1.2</span> Classes</h2>
<p>We say that the states <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> in <span class="math inline">\(S\)</span> <strong>intercommunicate</strong>, denoted
by <span class="math inline">\(i\leftrightarrow j\)</span> if <span class="math inline">\(i\to  j\)</span> <em>and</em> <span class="math inline">\(j\to i\)</span>. A set <span class="math inline">\(B\subseteq S\)</span> of states is called
<strong>irreducible</strong> if <span class="math inline">\(i\leftrightarrow j\)</span> for all <span class="math inline">\(i,j\in S\)</span>.</p>
<p>Unlike the relation of communication, the relation of intercommunication
is symmetric. Moreover, we have the following immediate property:
the relation <span class="math inline">\(\leftrightarrow\)</span> is an <em>equivalence relation</em> on <span class="math inline">\(S\)</span>, i.e., for all
<span class="math inline">\(i,j,k\in S\)</span>, we have</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(i\leftrightarrow i\)</span> (<em>reflexivity</em>) ,</p></li>
<li><p><span class="math inline">\(i\leftrightarrow j\)</span> implies <span class="math inline">\(j\leftrightarrow i\)</span> (<em>symmetry</em>), and</p></li>
<li><p><span class="math inline">\(i\leftrightarrow j, j\leftrightarrow k\)</span> implies <span class="math inline">\(i\leftrightarrow k\)</span> (<em>transitivity</em>).</p></li>
</ol>
<p>The fact that <span class="math inline">\(\leftrightarrow\)</span> is an equivalence relation allows us to split the
state-space <span class="math inline">\(S\)</span> into equivalence classes with respect to <span class="math inline">\(\leftrightarrow\)</span>. In
other words, we can write <span class="math display">\[S=S_1\cup S_2\cup S_3\cup \dots,\]</span> where
<span class="math inline">\(S_1, S_2, \dots\)</span> are mutually exclusive (disjoint) and all states in a
particular <span class="math inline">\(S_n\)</span> intercommunicate, while no two states from different
equivalence classes <span class="math inline">\(S_n\)</span> and <span class="math inline">\(S_m\)</span> do. The sets <span class="math inline">\(S_1, S_2, \dots\)</span> are
called <strong>classes</strong> of the chain <span class="math inline">\(\{X_n\}_{n\in {\mathbb{N}}_0}\)</span>. Equivalently, one can say
that classes are <em>maximal irreducible sets</em>, in the sense that they are
irreducible and no class is a subset of a (strictly larger) irreducible
set. A cookbook algorithm for class identification would involve the
following steps:</p>
<ol style="list-style-type: decimal">
<li><p>Start from an arbitrary state (call it <span class="math inline">\(1\)</span>).</p></li>
<li><p>Identify <em>all</em> states <span class="math inline">\(j\)</span> that intercommunicate with it (<span class="math inline">\(1\)</span>,
itself, always does).</p></li>
<li><p>That is your first class, call it <span class="math inline">\(C_1\)</span>. If there are no elements
left, then there is only one class <span class="math inline">\(C_1=S\)</span>. If there is an element
in <span class="math inline">\(S\setminus C_1\)</span>, repeat the procedure above starting from that
element.</p></li>
</ol>
<p>The notion of a class is especially useful in relation to another
natural concept: A set <span class="math inline">\(B\subseteq S\)</span> of states is said to be <strong>closed</strong> if <span class="math inline">\(i  \not\to j\)</span> for all <span class="math inline">\(i\in B\)</span> and all <span class="math inline">\(j\in S\setminus B\)</span>. In words, <span class="math inline">\(B\)</span> is closed if it is
impossible to get out of. A state
<span class="math inline">\(i\in S\)</span> such that the set <span class="math inline">\(\{i\}\)</span> is closed is called <strong>absorbing</strong>.</p>
<div class="problem">
<p>Show that a set <span class="math inline">\(B\)</span> of
states is closed if and only if <span class="math inline">\(p_{ij}=0\)</span> for all <span class="math inline">\(i\in B\)</span> and all
<span class="math inline">\(j\in B^c=S\setminus B\)</span>.</p>
</div>
<div class="solution">
<p>Suppose, first, that <span class="math inline">\(B\)</span> is closed. Then for <span class="math inline">\(i\in B\)</span> and <span class="math inline">\(j\in  B^c\)</span>, we have <span class="math inline">\(i\not\to j\)</span>, i.e., <span class="math inline">\(p^{(n)}_{ij}=0\)</span> for all <span class="math inline">\(n\in{\mathbb{N}}\)</span>. In
particular, <span class="math inline">\(p_{ij}=0\)</span>.</p>
<p>Conversely, suppose that <span class="math inline">\(p_{ij}=0\)</span> for all <span class="math inline">\(i\in B\)</span>, <span class="math inline">\(j\in B^c\)</span>. We
need to show that <span class="math inline">\(k\not\to l\)</span> (i.e. <span class="math inline">\(p^{(n)}_{kl}=0\)</span> for all <span class="math inline">\(n\in{\mathbb{N}}\)</span>) for
all <span class="math inline">\(k\in B\)</span>, <span class="math inline">\(l\in B^c\)</span>. Suppose, to the contrary, that there exist
<span class="math inline">\(k\in B\)</span> and <span class="math inline">\(l\in B^c\)</span> such that <span class="math inline">\(p^{(n)}_{kl}&gt;0\)</span> for some <span class="math inline">\(n\in {\mathbb{N}}\)</span>. That means that we can find a sequence of states
<span class="math display">\[k=i_0, i_1, \dots, i_n=l \text{ such that } p_{i_{m-1} i_{m}}&gt;0
\text{ forall }m = 1,\dots, n.\]</span> The first state, <span class="math inline">\(k=i_0\)</span> is in <span class="math inline">\(B\)</span> and the
last one, <span class="math inline">\(l=i_n\)</span>, is in <span class="math inline">\(B^c\)</span>. Therefore there must exist an index <span class="math inline">\(m\)</span>
such that <span class="math inline">\(i_{m-1}\in B\)</span> but <span class="math inline">\(i_{m}\in B^c\)</span>. We also know that
<span class="math inline">\(p_{i_m i_{m+1}}&gt;0\)</span>, which is in contradiction with out assumption that
<span class="math inline">\(p_{ij}=0\)</span> for all <span class="math inline">\(i\in B\)</span> and <span class="math inline">\(j\in B^c\)</span>.</p>
</div>
<p>Intuitively, a set of states is closed if it has the property that the
chain <span class="math inline">\(\{X_n\}_{n\in {\mathbb{N}}_0}\)</span> stays in it forever, once it enters it. In general, if
<span class="math inline">\(B\)</span> is closed, it does not have to follow that <span class="math inline">\(S\setminus B\)</span> is closed.
Also, a class does not have to be closed, and a closed set does not have
to be a class. Here is an example - consider
the following three sets of states in
the <em>tennis</em> chain of the previous lecture and:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(B=\{\text{``P1 wins&#39;&#39;}\}\)</span>: closed and a class, but
<span class="math inline">\(S\setminus B\)</span> is not closed</p></li>
<li><p><span class="math inline">\(B=S\setminus \{(0,0)\}\)</span>: closed, but not a class, and</p></li>
<li><p><span class="math inline">\(B=\{(0,0)\}\)</span>: class, but not closed.</p></li>
</ol>
<p>Not everything is lost as the following relationship always holds:</p>
<div class="problem">
<p>Show that every closed set <span class="math inline">\(B\)</span> is a union of one or more classes.</p>
</div>
<div class="solution">
<p>Let <span class="math inline">\(\hat{B}\)</span> be the union of all classes <span class="math inline">\(C\)</span> such that <span class="math inline">\(C\cap  B\not=\emptyset\)</span>. In other words, take all the elements of <span class="math inline">\(B\)</span> and
throw in all the states which intercommunicate with at least one of them. I claim that
<span class="math inline">\(\hat{B}=B\)</span>. Clearly, <span class="math inline">\(B\subset \hat{B}\)</span>, so we need to show that
<span class="math inline">\(\hat{B}\subseteq B\)</span>. Suppose, to the contrary, that there exists
<span class="math inline">\(j\in \hat{B}\setminus B\)</span>. By construction, <span class="math inline">\(j\)</span> intercommunicates with
some <span class="math inline">\(i\in B\)</span>. In particular <span class="math inline">\(i\to j\)</span>. By the closedness of <span class="math inline">\(B\)</span>, we must
have <span class="math inline">\(j\in B\)</span>. This is a contradiction with the assumptions that
<span class="math inline">\(j\in \hat{B}\setminus B\)</span>.</p>
<p>Note that the converse is not true: ust take the set
<span class="math inline">\(B=\{ (0,0), (0,15)\}\)</span> in the “tennis” example. It is a union of two
classes, but it is not closed.</p>
</div>
</div>
<div id="transience-and-recurrence" class="section level2">
<h2><span class="header-section-number">1.3</span> Transience and recurrence</h2>
<p>It is often important to know whether a Markov chain will ever return to
its initial state, and if so, how often. The notions of transience and
recurrence are used to address this questions.</p>
<p>We start by introducing a cousin <span class="math inline">\(T_j(1)\)</span> of the first hitting time <span class="math inline">\(\tau_1\)</span>.
The <strong>(first) visit time</strong> to state <span class="math inline">\(j\)</span>, denoted by <span class="math inline">\(T_j(1)\)</span> is defined
as <span class="math display">\[T_j(1) = \min \{ n\in{\mathbb{N}}\, : \, X_n=j\}.\]</span> As usual <span class="math inline">\(T_j(1)=\infty\)</span> if
<span class="math inline">\(X_n\not = j\)</span> for all <span class="math inline">\(n\in{\mathbb{N}}\)</span>.
Similarly, second, third, etc., visit times are defined as follows:
<span class="math display">\[\begin{aligned}
  T_j(2) &amp;= \min \{ n&gt;T_j(1)\, : \, X_n=j\}, \\
  T_j(3) &amp;= \min \{ n&gt;T_j(2)\, : \, X_n=j\}, \text{ etc., }\end{aligned}\]</span>
with the understanding that if <span class="math inline">\(T_j(n)=\infty\)</span>, then also
<span class="math inline">\(T_j(m)=\infty\)</span> for all <span class="math inline">\(m&gt;n\)</span>.</p>
<p>Note that the definition of the random variable <span class="math inline">\(T_j(1)\)</span> differs from
the definition of <span class="math inline">\(\tau_j\)</span> in that the minimum here is taken over the
set <span class="math inline">\({\mathbb{N}}\)</span> of natural numbers, while the set of non-negative integers
<span class="math inline">\({\mathbb{N}}_0\)</span> is used for <span class="math inline">\(\tau_j\)</span>. When <span class="math inline">\(X_0\not = j\)</span>, the hitting time
<span class="math inline">\(\tau_j\)</span> and the first visit time <span class="math inline">\(T_j(1)\)</span> coincide. The important
difference occurs only when <span class="math inline">\(X_0=j\)</span>. In that case <span class="math inline">\(\tau_j=0\)</span> (we are
already there), but it is always true that <span class="math inline">\(T_j(1)\geq 1\)</span>. It can even
happen that <span class="math inline">\({\mathbb{P}}_j[T_j(1)=\infty]=1\)</span>. If you want an example, take any state in the
deterministically monotone chain.</p>
<p>A state <span class="math inline">\(i\in S\)</span> is said to be</p>
<ol style="list-style-type: decimal">
<li><p><strong>recurrent</strong> if <span class="math inline">\({\mathbb{P}}_i[T_i(1)&lt;\infty]=1\)</span>,</p></li>
<li><p><strong>positive recurrent</strong> if <span class="math inline">\({\mathbb{E}}_i[T_i(1)]&lt;\infty\)</span></p></li>
<li><p><strong>null recurrent</strong> if it is recurrent, but not positive recurrent,</p></li>
<li><p><strong>transient</strong> if it is not recurrent.</p></li>
</ol>
<p>A state is recurrent if we are sure we will come back to it eventually
(with probability 1). It is positive recurrent if it is recurrent and
the time between two consecutive visits has finite expectation. Null
recurrence means the we will return, but the waiting time may be very
long. A state is transient if there is a positive chance (however small)
that the chain will never return to it.</p>
<div id="the-return-theorem" class="section level3">
<h3><span class="header-section-number">1.3.1</span> The Return Theorem</h3>
<p>The definition of recurrence from above is conceptually simple, but it
gives us no clue about how to actually go about deciding whether a
particular state in a specific Markov chain is recurrent. A criterion
stated entirely in terms of the transition matrix <span class="math inline">\(P\)</span> would be nice.
Before we give it, we need to introduce some notation. and prove an important theorem.
Given a state
<span class="math inline">\(i\)</span>, let <span class="math inline">\(f_i\)</span> denote the probability that the chain will visit <span class="math inline">\(i\)</span>
again, if it starts there, i.e., <span class="math display">\[f_i = {\mathbb{P}}_i[ T_i(1) &lt; \infty].\]</span>
Clearly, <span class="math inline">\(i\)</span> is recurrent if and only if <span class="math inline">\(f_i=1\)</span>.</p>
<p>The interesting thing is that every time our chain visits the state <span class="math inline">\(i\)</span>,
its future evolution is independent from the past (except for the name
of the current state) and it behaves exactly like a new and independent
chain started from <span class="math inline">\(i\)</span> would. This is a special case of so-called
<strong>strong Markov property</strong> which states that the (usual) Markov property
also holds at stopping times (and not only fixed times <span class="math inline">\(n\)</span>). We will not
prove this property it these notes, but we will gladly use it to prove
the following dichotomy:</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-5" class="theorem"><strong>Theorem 1.1  </strong></span>(The “Return” Theorem)
Let
<span class="math inline">\(\{X_n\}_{n\in {\mathbb{N}}_0}\)</span> be a Markov chain on a countable state space <span class="math inline">\(S\)</span>, with the
(deterministic) initial state <span class="math inline">\(X_0=i\)</span>. Then exactly one of the following
two statements hold:</p>
<ol style="list-style-type: decimal">
<li><p>either the chain will return to <span class="math inline">\(i\)</span> infinitely many times, or</p></li>
<li><p>the chain will return to <span class="math inline">\(i\)</span> a finite number <span class="math inline">\(N_i\)</span> of times, where
<span class="math inline">\(N_i\)</span> is geometrically distributed random variable with parameter <span class="math inline">\(f_i\)</span>, where
<span class="math inline">\(f_i={\mathbb{P}}_i[T_i(1)&lt;\infty]\)</span>.</p></li>
</ol>
In the first case, <span class="math inline">\(i\)</span> is recurrent and, in the second, it is transient.
</div>



<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> If <span class="math inline">\(f_i=1\)</span>, then <span class="math inline">\(X\)</span> is guaranteed to return to <span class="math inline">\(i\)</span> at least once. When
that happens, however, the strong Markov property “deletes” the past,
and the process “renews” itself. This puts us back in the original
situation where we are looking at a chain which starts at <span class="math inline">\(i\)</span> and is
guaranteed to return there at least once. Continuing like that, we get a
whole infinite sequence of stopping times <span class="math display">\[T_i(1) &lt; T_i(2) &lt; \dots\]</span> at
which <span class="math inline">\(X\)</span> finds itself at <span class="math inline">\(i\)</span>.</p>
If <span class="math inline">\(f_i&lt;1\)</span>, a similar story can be told, but with a significant
difference. Every time <span class="math inline">\(X\)</span> returns to <span class="math inline">\(i\)</span>, there is a probability
<span class="math inline">\(1-f_i\)</span> that it will never come back to <span class="math inline">\(i\)</span>, and, this is independent of
the past behavior. If we think of the return to <span class="math inline">\(i\)</span> as a success, the
number of successes before the first failure, i.e., the number of return
visits to <span class="math inline">\(i\)</span>, is nothing but a geometrically distributed random
variable with parameter <span class="math inline">\(f_i\)</span>. Q.E.D.
</div>

<p><br></p>
<p>The following interesting fact follows (almost) directly from the Return Theorem:</p>
<div class="problem">
<p>Suppose that the state space <span class="math inline">\(S\)</span> is finite. Show that there exists at least
one recurrent state.</p>
</div>
<div class="solution">
<p>We argue by contradiction and assume that all the states are transient.
We claim that, in that case, the total number of visits <span class="math inline">\(N_i\)</span> to each
state <span class="math inline">\(i\)</span> is always finite, no matter what state <span class="math inline">\(i_0\)</span> we start from.
Indeed, if <span class="math inline">\(i=i_0\)</span> that is precisely the
conclusion the Return Theorem above. For a state <span class="math inline">\(i\ne i_0\)</span>, the number of
visits is either <span class="math inline">\(0\)</span> - if we never even get to <span class="math inline">\(i\)</span>, or <span class="math inline">\(1+N_{i}\)</span> if we
do. In either case, it is a finite number (not <span class="math inline">\(\infty\)</span>).</p>
<p>Therefore the sum <span class="math inline">\(\sum_{i\in S} N_i\)</span> is also finite - a contradiction
with the fact that there are infinitely many time instances <span class="math inline">\(n\in{\mathbb{N}}_0\)</span>,
and that the chain must be in some state in each one of them.</p>
</div>
<p>If <span class="math inline">\(S\)</span> is not finite, it is not true that recurrent states must exist.
Just think of the Deterministically-Monotone Chain or
the random walk with <span class="math inline">\(p\not=\tfrac{1}{2}\)</span>. All states are transitive there.</p>
</div>
<div id="a-recurrence-criterion" class="section level3">
<h3><span class="header-section-number">1.3.2</span> A recurrence criterion</h3>
<p>Perhaps the most important consequence of the Return Theorem is the following
criterion for recurrence of Markov chains on finite or countable state spaces:</p>

<div class="theorem">
<span id="thm:unnamed-chunk-7" class="theorem"><strong>Theorem 1.2  </strong></span>(The Recurrence Criterion)
A state <span class="math inline">\(i\in S\)</span>
is recurrent if and only if <span class="math display">\[\sum_{n\in{\mathbb{N}}} p^{(n)}_{ii}=\infty.\]</span>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof. </em></span> Let <span class="math inline">\(N_i\)</span> denote the total number (finite or <span class="math inline">\(\infty\)</span>) of visits to the state <span class="math inline">\(i\)</span>, with the initial visit at time <span class="math inline">\(0\)</span> not counted.
We can write <span class="math inline">\(N_i\)</span> as an infinite sum as follows
<span class="math display">\[N_i = \sum_{n=1}^{\infty} \mathbf{1}_{\{X_n = i\}}.\]</span>
Taking the
expectation yields
<span class="math display">\[{\mathbb{E}}[N_i] = {\mathbb{E}}_i[ \sum_{n=1}^{\infty} \mathbf{1}_{\{X_n=i\}}] = \sum_{n=1}^{\infty} {\mathbb{E}}_i[ \mathbf{1}_{\{X_n=i\}}] = \sum_{n=1}^{\infty} {\mathbb{P}}_i[
 X_n=i] = \sum_{n=1}^{\infty} p^{(n)}_{ii},\]</span> where we used the intuitively acceptable (but not rigorously proven)
fact that <span class="math inline">\({\mathbb{E}}_i\)</span> and an <em>infinite</em> sum can be switched.</p>
If <span class="math inline">\(i\)</span> is transient, i.e., if
<span class="math inline">\(f_i&lt;1\)</span>, the Return Theorem and the formula for the expected value of a geometric distribution imply that
<span class="math display">\[{\mathbb{E}}_i[N_i] = \frac{f_i}{1-f_i}&lt;\infty, \text{ and so }
 \sum_{n=1}^{\infty} p^{(n)}_{ii} = {\mathbb{E}}_i[N_i]&lt;\infty.\]</span> On the other
hand, if <span class="math inline">\(i\)</span> is recurrent, the Return Theorem states that <span class="math inline">\(N_i=\infty\)</span>. Hence,
<span class="math display">\[\sum_{n=1}^{\infty} p^{(n)}_{ii}={\mathbb{E}}_i[N_i]=\infty. \text{ Q.E.D. }\]</span>
</div>

<p><em>Remark.</em> The central idea behind the proof of the recurrence criterion is the following: we managed tell
whether or not <span class="math inline">\(N_i = \infty\)</span> by checking whether <span class="math inline">\({\mathbb{E}}[N_i]=\infty\)</span> or not.
This is, however, not something that can be done for any old random variable taking values in <span class="math inline">\({\mathbb{N}}_0 \cup \{\infty\}\)</span>.
If <span class="math inline">\({\mathbb{E}}[N]&lt;\infty\)</span>, then, clearly <span class="math inline">\({\mathbb{P}}[N=\infty]=0\)</span> so that <span class="math inline">\(N\)</span> only
takes values in <span class="math inline">\({\mathbb{N}}_0\)</span>. On the other hand, it is not true that
<span class="math inline">\({\mathbb{P}}[N=\infty]=0\)</span> implies that <span class="math inline">\({\mathbb{E}}[N]&lt;\infty\)</span>. It suffices to take a
random variable with the following distribution
<span class="math display">\[{\mathbb{P}}[ N = n] = c/n^2 \text{ for }n\in{\mathbb{N}},\]</span> where the constant <span class="math inline">\(c\)</span> is chosen
so that <span class="math inline">\(\sum_n c/n^2 =1\)</span> (in fact, we can compute that <span class="math inline">\(c=6/\pi^2\)</span>
explicitly in this case). The expected value of <span class="math inline">\(N\)</span> is given by
<span class="math display">\[{\mathbb{E}}[N] = \sum_{n=1}^{\infty} n {\mathbb{P}}[N=n] = c \sum_{n=1}^{\infty} \frac{1}{n}
  = \infty.\]</span> The message is that, in general, you cannot detect
whether something happened infinitely many times or not based only on
its expectation.</p>
<p>Such a detection, however, becomes possible in the
special case when <span class="math inline">\(N=N_i\)</span> denotes the total number of returns to the
state <span class="math inline">\(i\)</span> of a Markov chain. This is exactly the content of proof of
the Return Theorem above: each time the chain leaves <span class="math inline">\(i\)</span>, it
comes back to it (or does not) with the same probability, independently
of the past. This gives us extra information about the random variable
<span class="math inline">\(N\)</span> (namely that it is either infinite with probability <span class="math inline">\(1\)</span> or
geometrically distributed) and allows us to test its finiteness by using
the expected value only.</p>
</div>
<div id="polyas-theorem" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Polya’s theorem</h3>
<p>Here is an application of our recurrence criterion - a beautiful and
unexpected result of George Pólya from 1921.</p>
<p>In addition to the simple symmetric random walk on the line (<span class="math inline">\(d=1\)</span>) we
studied before, one can consider random walks whose values are in the
plane (<span class="math inline">\(d=2\)</span>), the space (<span class="math inline">\(d=3\)</span>), etc. These are usually defined as
follows: the random walk in <span class="math inline">\(d\)</span> dimensions is the Markov chain with the
state space <span class="math inline">\(S={\mathbb{Z}}^d\)</span> and the following transitions:<br />
starting from the state <span class="math inline">\((x_1,\dots, x_d)\)</span>, it
picks one of its <span class="math inline">\(2d\)</span> neighbors <span class="math inline">\((x_1+1,\dots, x_d)\)</span>,
<span class="math inline">\((x_1-1,\dots, x_d)\)</span>, <span class="math inline">\((x_1, x_2+1,\dots, x_d)\)</span>,
<span class="math inline">\((x_1, x_2-1,\dots, x_d)\)</span>, …, <span class="math inline">\((x_1,\dots, x_d+1)\)</span>, <span class="math inline">\((x_1,\dots, x_d-1)\)</span> randomly and uniformly and moves there. For
illustration, here is a picture of a path of a two-dimensional random walk; as time progresses, the color of the edges goes from black to orange, edges traversed
multiple times are darker, dots mark the position of the walk at time <span class="math inline">\(n=0\)</span> (the black round dot) and at time <span class="math inline">\(n=1000\)</span> (orange square dot):</p>
<center>
<img src="_main_files/figure-html/unnamed-chunk-9-1.png" width="130%" style="display: block; margin: auto;" />
</center>
<p>Polya’s (and our) goal was to study the recurrence properties of the
<span class="math inline">\(d\)</span>-dimensional random walk. We already
know that the simple symmetric random walk on <span class="math inline">\({\mathbb{Z}}\)</span> is recurrent (i.e.,
every <span class="math inline">\(i\in {\mathbb{Z}}\)</span> is a recurrent state). The easiest way to proceed when
<span class="math inline">\(d\geq 2\)</span> is to use the recurrence criterion we proved above.
We start by estimating the values <span class="math inline">\(p^{(n)}_{ii}\)</span>, for
<span class="math inline">\(n\in{\mathbb{N}}\)</span>. By symmetry, we can focus on the origin, i.e., it is enough to
estimate, for each <span class="math inline">\(n\in{\mathbb{N}}\)</span>, the magnitude of
<span class="math display">\[p^{(n)}= p^{(n)}_{00}= {\mathbb{P}}_{0}[ X_n=(0,0,\dots, 0)].\]</span> As we learned some time ago,
this probability can be computed by counting all “trajectories” from <span class="math inline">\((0,\dots, 0)\)</span>
that return to <span class="math inline">\((0,\dots, 0)\)</span> in <span class="math inline">\(n\)</span> steps. First of all, it is clear that <span class="math inline">\(n\)</span> needs to
be even, i.e., <span class="math inline">\(n=2m\)</span>, for some <span class="math inline">\(m\in{\mathbb{N}}\)</span>. It helps if we think of any
trajectory as a sequence of “increments” <span class="math inline">\(\xi_1,\dots, \xi_n\)</span>, where
each <span class="math inline">\(\xi_i\)</span> takes its value in the set <span class="math inline">\(\{1,-1,2,-2,\dots, d, -d\}\)</span>.
In words, <span class="math inline">\(\xi_i= +k\)</span> if the <span class="math inline">\(k\)</span>-th coordinate increases by <span class="math inline">\(1\)</span> on the
<span class="math inline">\(i\)</span>-th step, and <span class="math inline">\(\xi_i=-k\)</span>, if the <span class="math inline">\(k\)</span>-th coordinate decreases<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>This way, the problem becomes combinatorial:</p>
<p><em>In how many ways can we put one element of the set
<span class="math inline">\(\{1,-1,2,-2, \dots, d,-d\}\)</span> into each of <span class="math inline">\(n=2m\)</span> boxes so that the
number of boxes with <span class="math inline">\(k\)</span> in them equals to the number of boxes with <span class="math inline">\(-k\)</span>
in them?</em></p>
<p>To get the answer, we start by fixing a possible “count” <span class="math inline">\((i_1,\dots,  i_d)\)</span>, satisfying <span class="math inline">\(i_1+\dots+i_d=m\)</span> of the number of times each
of the values in <span class="math inline">\(\{1,2,\dots, d\}\)</span> occurs. These values have to be
placed in <span class="math inline">\(m\)</span> of the <span class="math inline">\(2m\)</span> slots and their negatives (possibly in a
different order) in the remaining <span class="math inline">\(m\)</span> slots. So, first, we choose the
“positive” slots (in <span class="math inline">\(\binom{2m}{m}\)</span> ways), and then distribute <span class="math inline">\(i_1\)</span>
“ones”, <span class="math inline">\(i_2\)</span> “twos”, etc., in those slots; this can be done in<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>
<span class="math display">\[\binom{ m }{ i_1 i_2 \dots i_d}\]</span> ways. This is also the number of
ways we can distribute the negative “ones”, “twos”, etc., in the
remaining slots. All in all, for fixed <span class="math inline">\(i_1,i_2,\dots, i_d\)</span>, all of this
can be done in <span class="math display">\[\binom{2m}{m} \binom{ m }{ i_1 i_2 \dots i_d}^2\]</span> ways.
Remembering that each path has the probability <span class="math inline">\((2d)^{-2m}\)</span>, and summing
over all <span class="math inline">\(i_1,\dots, i_d\)</span> with <span class="math inline">\(i_1+\dots+i_d=m\)</span>, we get
<span class="math display" id="eq:p2m">\[\begin{equation}
  p^{(2m)} = \frac{1}{(2d)^{2m}} \binom{2m}{m} \sum_{i_1+\dots+i_d=m}
        \binom{ m }{ i_1 i_2 \dots i_d}^2.
\tag{1.1}
\end{equation}\]</span>
This expression looks so complicated that we better start examining is for
particular values of <span class="math inline">\(d\)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>For <span class="math inline">\(d=1\)</span>, the expression above simplifies to <span class="math inline">\(p^{(2m)} = \frac{1}{4^{m}} \binom{2m}{m}\)</span>. It is
still too complicated sum over all <span class="math inline">\(m\in{\mathbb{N}}\)</span>, but we can simplify it
further by using Stirling’s formula
<span class="math display">\[n! \sim \sqrt{2\pi n} \big(\tfrac{n}{e}\big)^n,\]</span> where <span class="math inline">\(a_n \sim b_n\)</span>
means <span class="math inline">\(\lim_{n\to\infty} a_n/b_n=1\)</span>. Indeed, from there,
<span class="math display">\[\label{equ:binom}
 \begin{split}
\binom{2m}{m} \sim \frac{4^m}{ \sqrt{\pi m}},
 \end{split} \text{ and so } p^{(2m)} \sim  \frac{1}{\sqrt{m\pi}}.\]</span> That means that <span class="math inline">\(p^{(m)}\)</span> behaves
li a <span class="math inline">\(p\)</span>-series with <span class="math inline">\(p=1/2\)</span> which we know is divergent. Therefore,
<span class="math display">\[\sum_{m=1}^{\infty} p^{(2m)} = \infty,\]</span>
and we recover our previous conclusion that the simple symmetric random
walk is, indeed, recurrent.</p></li>
<li><p>Moving on to the case <span class="math inline">\(d= 2\)</span>, we notice that the sum of the multinomial
coefficients in <a href="#eq:p2m">(1.1)</a> no longer equals <span class="math inline">\(1\)</span>; in fact it is given
by<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>
<span class="math display">\[\label{equ:Van}
 \begin{split}
\sum_{i=0}^{m} \binom{m}{i}^2 = \binom{2m}{m},
 \end{split}\]</span> and, so,
<span class="math display">\[p^{(2m)} = \frac{1}{16^m} \Big( \frac{4^m}{\sqrt{\pi m}} \Big)^2 \sim
\frac{1}{\pi m}  \text{ implying that  } \sum_{m=1}^{\infty} p^{(2m)}=\infty,\]</span> which
which, in turn, implies that the two-dimensional random walk is also recurrent.</p></li>
<li><p>How about <span class="math inline">\(d\geq 3\)</span>? Things are even more complicated now. The
multinomial sum in <a href="#eq:p2m">(1.1)</a> above does not admit a nice closed-form expression as in
the case <span class="math inline">\(d=2\)</span>, so
we need to do some estimates; these are a bit tedious so we skip them,
but report the punchline, which is that <span class="math display">\[p^{(2m)} 
\sim C \Big(
\tfrac{3}{m} \Big)^{3/2},\]</span> for some constant <span class="math inline">\(C\)</span>. This is where it gets
interesting: this is a <span class="math inline">\(p\)</span>-series which <strong>converges</strong>:
<span class="math display">\[\sum_{m=1}^{\infty} p^{(2m)}&lt;\infty,\]</span> and, so, the random walk is
transient for <span class="math inline">\(d=3\)</span>. This is enough to conclude that the random walk is
transient for all <span class="math inline">\(d\geq 3\)</span>, too (why?).</p></li>
</ol>
<p>To summarize</p>

<div class="theorem">
<span id="thm:unnamed-chunk-10" class="theorem"><strong>Theorem 1.3  </strong></span>(Polya)
The simple symmetric random walk is recurrent for <span class="math inline">\(d=1,2\)</span>, but transient
for <span class="math inline">\(d\geq 3\)</span>.
</div>

<p><br>
In the words of Shizuo Kakutani</p>
<blockquote>
<p><em>A drunk man will find his way home, but a drunk bird may get lost
forever.</em></p>
</blockquote>
</div>
</div>
<div id="class-properties" class="section level2">
<h2><span class="header-section-number">1.4</span> Class properties</h2>
<p>COMING SOON</p>
</div>
<div id="a-few-examples" class="section level2">
<h2><span class="header-section-number">1.5</span> A few Examples</h2>
<p>COMING SOON</p>
</div>
<div id="additional-problems-for-chapter-6" class="section level2">
<h2><span class="header-section-number">1.6</span> Additional problems for Chapter 6</h2>
<p>⬇︎ In case you were wondering, the text below belongs to footnotes from somewhere high above.⬇︎</p>

</div>
</div>

















<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>For <span class="math inline">\(d=2\)</span> we could have used the values “up”, “down”, “left” and
“’right”, for <span class="math inline">\(1,-1,2\)</span> or <span class="math inline">\(-2\)</span>, respectively. In dimension <span class="math inline">\(3\)</span>, we
could have added “forward” and “backward”, but we run out of words
for directions for larger <span class="math inline">\(d\)</span>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p> <span class="math inline">\(\binom{m}{i_1  \dots i_d}\)</span> is called the <em>multinomial coefficient</em>. It
counts the number of ways we can color <span class="math inline">\(m\)</span> objects into one of <span class="math inline">\(d\)</span>
colors such that there are <span class="math inline">\(i_1\)</span> objects of color <span class="math inline">\(1\)</span>, <span class="math inline">\(i_2\)</span> of
color <span class="math inline">\(2\)</span>, etc. It is a generalization of the binomial coefficient
and its value is given by
<span class="math display">\[\binom{ m }{ i_1 i_2 \dots i_d} = \frac{m!}{i_1! i_2!\dots
            i_d!}.\]</span><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Why is this identity true? Can you give a counting argument?<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>


    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": false,
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"search": true,
"toc_depth": null
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
