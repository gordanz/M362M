[
["index.html", "Lecture notes for \"Introduction to Stochastic Processes\" Preface", " Lecture notes for \"Introduction to Stochastic Processes\" Gordan Zitkovic last updated - 2020-09-09 Preface This is an always-evolving set of lecture notes for Introduction to Stochastic Processes (M362M). It should start with me explaining what stochastic processes are. Instead, here is a list of several questions you will be able to give answers to when you complete this course. Question 1 In a simplistic model, the price of a share of a stock goes either up or down by \\(\\$1\\) each day, with probability \\(1/2\\). You own a single share whose value today is \\(\\$100\\), so that its tomorrow’s price will be \\(\\$101\\) or \\(\\$99\\) with probability \\(1/2\\), etc. Your strategy is to hold onto your share until one of the following two things happen: you go bankrupt (the stock price hits \\(0\\)), or you make a \\(\\$50\\) dollar profit (the stock price hits \\(\\$150\\).) How likely is it that you will make a profit before you go bankrupt? How long will it take? Is it possible that it takes forever, i.e., that the stock price hovers between \\(\\$1\\) and \\(\\$149\\) forever? Question 2. A person carrying a certain disease infects a random number of people in a week, and then stops being infectious. Each of the infected people transmits the disease in the same way, etc. Suppose that the number of people each (infectious) individual infects is either \\(0\\), \\(1\\) or \\(2\\) or \\(3\\), each with probability \\(1/4\\) and that different infectious individuals may infect different number of people and behave independently of each other. What is the probability that the disease will ever be eradicated? What is the probability that every single individual in the population of \\(328,000,000\\) will eventually be infected? Question 3. In a game of tennis, Player \\(1\\) wins against Player \\(2\\) in each rally (the smallest chunk of the match that leads to point, i.e., to a score change from \\(15-30\\) to \\(30-30\\), for example) with probability \\(p\\). What is the probability that Player \\(1\\) wins a game (the chunk of the match that leads to a score change such as \\(5-3\\) to \\(6-3\\) within a set)? a set? the entire match? Is the game of tennis set up in such a way that is amplifies or reduces the difference in skill between players? Question 4. A knight starts in the lower left corner of the chess board and starts moving ``randomly’’. That means that from any position, it chooses one of the possible (legal) moves and takes it, with all legal moves having the same probability. It keeps doing the same thing until it comes back to the square it started from. What is the expected number of moves the knight will make before it returns to “square one”? How about the same problem, but using a different chess piece? Which one do you think will come back is the smallest (expected) number of steps? (*) How about the same problem, but until all squares have been visited at least once? Question 5. How does Google search work? "],
["intro.html", "Chapter 1 An intro to R and RStudio 1.1 Setting up an R environment on your computer 1.2 Learning the basics of R 1.3 Problems", " Chapter 1 An intro to R and RStudio 1.1 Setting up an R environment on your computer 1.1.1 Installing R Learning basic R is an important part of this course, and the first order of business is to download and install an R distribution on your personal computer. We will be using RStudio as an IDE (integrated development environment). Like R itself, it is free and readily available for all major platforms. To download R to your computer, go to https://cloud.r-project.org and download the version of R for your operating system (Windows, Mac or Linux). If you are on a Mac, you want the “Latest release” which, at the time of writing, is 4.0.2. On Windows, follow the link “install R for the first time”. We are not going to do any cutting edge stuff in this class, so an older release should be fine, too, if you happen to have it already installed on your system. Once you download the installation file (.pkg on a Mac or .exe on Windows), run it and follow instructions. If you are running Linux, you don’t need me to tell you what to do. Once it is successfully installed, don’t run the installed app. We will use RStudio for that. 1.1.2 Installing RStudio To install RStudio, go to https://rstudio.com/products/rstudio/download/. There are several versions to choose from - the one you are looking for is “RStudio desktop - Free”. After you download and install it, you are ready to run it. When it opens, you will see something like this The part on the left is called the console and that is (one of the places) where you enter commands. Before you do, it is important to adjust a few settings. Open the options window by navigating to to Tools-&gt;Global Options. In there, uncheck “Restore .RData into workspace on startup” and set “Save workspace to .RData on exit” to “Never”, as shown below: This way, R will not pollute your environment with values you defined two weeks ago and completely forgot about. These settings are really an atavism and serve no purpose (for users like us) other than to introduce hard-to-track bugs. There are many other settings you can play with in RStudio, but the two I mentioned above are the only ones that I really recommend setting as soon as you install it. 1.1.3 Installing basic packages Finally, we need to install several R packages we will be using (mostly implicitly) during the class. First, run the following command in your console install.packages( &quot;tidyverse&quot;) This will install a number of useful packages and should only take about a minute or two. The next part is a bit longer, and can take up to 15 minutes if you have a slow computer/internet connection. You only have to do it once, though. Skip both steps involving tinytex below if you have LaTeX already installed on your system1. Start with install.packages(&quot;tinytex&quot;) followed by tinytex::install_tinytex() Note that if you go to the top right corner of each of the code blocks (gray boxes) containing instructions above, an icon will appear. If you click on it, it will copy the content of the box into your clipboard, and you can simply paste it into RStudio. You can do that with any code block in these notes. 1.2 Learning the basics of R Once R and RStudio are on your computer, it is time to get acquainted with the basics of R. This class is not about the finer points of R itself, and I will try to make your R experience as smooth as possible. After all, R is a tool that will help us explore and understand stochastic processes. Having said that, it is important to realize that R is a powerful programming language specifically created for statistical and probabilistic applications. Some knowledge of R is a valuable skill to have in today’s job market, and you should take this opportunity to learn it. The best way, of course, is by using it, but before you start, you need to know the very basics. Don’t worry, R is very user friendly and easy to get started in. In addition, it has been around for a long time (its predecessor S appeared in 1976) and is extremely well documented - google introduction to R or a similar phrase, and you will get lots of useful hits. My plan is to give you a bare minimum in the next few paragraphs, and then to explain additional R concepts as we need them. This way, you will not be overwhelmed right from the start, and you will get a bit of a mathematical context as you learn more. Conversely, learning R commands will help with the math, too. 1.2.1 The console, Scripts and R Notebooks There at least three different ways of inputting commands into R - through console, scripts and R-notebooks. The console, as I already mentioned, is a window in RStudio where you can enter your R commands one by one. As a command is entered (and enter pressed) R will run it and display the result below. A typical console session looks like this If you define a variable in a command, it will be available in all the subsequent commands. This way of interacting with R is perfect for quick-and-dirty computations and, what is somewhat euphemistically called “prototyping”. In other words, this way you are using R as a calculator. There is another reason why you might be using the console. It is perfect for package installation and for help-related commands. If you type help('log'), the output will appear in the Help pane on the right. You can also see all the available variables in the Environment pane on the (top) right. As your needs increase, you will need more complex (and longer) code to meet them. This is where scripts come in. They are text files (but have the extension .R) that hold R code. Scripts can run as a whole, and be saved for later. To create a new script, go to File-&gt;New File-&gt;R Script. That will split your RStudio window in two: The top part will become a script editor, and your console will shrink to occupy the bottom part. You can write you code in there, edit and update it, and then run the whole script by clicking on Source, or pressing the associated shortcut key. Inspired by Python Jupyter notebooks, R notebooks are a creature somewhere between scripts and the console, but also have some features of their own. An R notebook is nothing other than a specially formatted text file which contains chunks of R code mixed with regular text. You can think of these chunks as mini scripts. What differentiates them from scripts is that chunks can be executed (evaluated) and the output becomes a part of the notebook: R notebooks are R’s implementation of literate programming. The idea is that documentation should be written at the same time as the program itself. As far as this course if concerned, R notebooks are just the right medium for homework and exam submission. You can run code and provide the interpretation of its output in a single document. See here for more information. Each chapter in these lecture notes is an R notebook! 1.2.2 Asking for help The most important thing about learning R (and many other things, for that matter) is knowing whom (and how) to ask for help. Luckily, R is a well established language, and you can get a lot of information by simply googling your problem. For example, if you google logarithm in R the top hit (at the time of writing) gives a nice overview and some examples. Another way to get information about a command or a concept in R is to use the command help. For example, if you input help(\"log\") or ?log in your console, the right hand of your screen will display information on the function log and some of its cousins. Almost every help entry has examples at the bottom, and that is where I always go first. 1.2.3 Vectors Objects we will be manipulating in this class are almost exclusively vectors and matrices. The simplest vectors are those that have a single component, in other words, numbers. In R, you can assign a number to a variable using two different notations. Both a &lt;- 1 and a = 1 will assign the value \\(1\\) to the variable a. If you want to create a longer vector, you can use the concatenation operator c as follows: x = c(1, 2, 3, 4) Once you evaluate the above in your console, the value of x is stored and you can access it by using the command print print(x) ## [1] 1 2 3 4 or simply evaluating x itself: x ## [1] 1 2 3 4 Unlike all code blocks above them, the last two contain both input and output. It is standard not to mark the output by any symbol (like the usual &gt;), and to mark the output by ## which otherwise marks comments. This way, you can copy any code block from these notes and paste it into the console (or your script) without having to modify it in any way. Try it! We built the vector x above by concatenating four numbers (vectors of length 1). You can concatenate vectors of different sizes, too: a = c(1, 2, 3) b = c(4, 5, 6) (x = c(a, b, 7)) ## [1] 1 2 3 4 5 6 7 You may be wondering why I put x = c(a,b,7) in parentheses. Without them, x would still become (1,2,3,4,5,6,7), but its value would not be printed out. A statement in parentheses is not only evaluated, but its result is also printed out. This way, (x = 2+3) is equivalent to x = 2+3 followed by x or print(x). Vectors can contain things other than numbers. Strings, for example: (x = c(&quot;Picard&quot;, &quot;Data&quot;, &quot;Geordi&quot;)) ## [1] &quot;Picard&quot; &quot;Data&quot; &quot;Geordi&quot; If you need a vector consisting of consecutive numbers, use the colon : notation: 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 For sequences of equally spaced numbers, use the command seq (check its help for details) seq(from = 5, to = 20, by = 3) ## [1] 5 8 11 14 17 20 An important feature or R is that many of its functions are vectorized. That means that if you give such a function a vector as an argument, the returned value will be a vector of results of that operation performed element by element. For example x = c(10, 20, 30) y = c(2, 4, 5) x + y ## [1] 12 24 35 x * y ## [1] 20 80 150 x^2 ## [1] 100 400 900 cos(x) ## [1] -0.8390715 0.4080821 0.1542514 The vectors do not need to be of the same size. R uses the recycling rule - it recycles the values of the shorter one, starting from the beginning, until its size matches the longer one: x = c(10, 20, 30, 40, 50, 60) y = c(1, 3) x + y ## [1] 11 23 31 43 51 63 The case where the shorter vector is of length 1 is particularly useful: x = c(10, 20, 30, 40) x + 1 ## [1] 11 21 31 41 x * (-2) ## [1] -20 -40 -60 -80 Extracting parts of the vector is accomplished by using the indexing operator []. Here are some examples (what do negative numbers do?) x = c(10, 20, 30, 40, 50) x[1] ## [1] 10 x[c(1, 2)] ## [1] 10 20 x[-1] ## [1] 20 30 40 50 x[-c(3, 4)] ## [1] 10 20 50 x[1:4] ## [1] 10 20 30 40 x[c(1, 1, 2, 2, 5, 4)] ## [1] 10 10 20 20 50 40 People familiar with Python should be aware of the following two differences: 1. indexing starts at 1 and not 0, and 2. negative indexing removes components; it does not start counting from the end! It is important to note that the thing you put inside [] needs to be a vector itself. The above examples all dealt with numerical indices, but you can use logical indices, too. A variable is said to be logical or Boolean if it can take only one of the two values TRUE or FALSE. A vector whose components are all logical, are called, of course, logical vectors. You can think of logical indexing as the operation where you go through your original vector, and choose which components you want to keep (TRUE) and which you want the throw away (FALSE). For example x = c(10, 20, 30, 40, 50) y = c(TRUE, FALSE, FALSE, TRUE, TRUE) x[y] ## [1] 10 40 50 This is especially useful when used together with the comparison operators. The expressions like x &lt; y or x == y are operators2 in R, just like x + y or x / y. The difference is that &lt; and == return logical values. For example 1 == 2 ## [1] FALSE 3 &gt; 4 ## [1] FALSE 3 &gt;= 2 ## [1] TRUE These operators are vectorized, so you can do things like this x = c(1, 2, 3, 4, 5) y = c(1, 3, 3, 2, 5) x == y ## [1] TRUE FALSE TRUE FALSE TRUE or, using recycling, x = c(1, 2, 3, 4, 5) x &gt; 3 ## [1] FALSE FALSE FALSE TRUE TRUE Let’s combine that with indexing. Suppose that we want to keep only the values greater than 4 in the vector x. The vector y = ( x &gt; 4 ) is going to be of the same length as x and contain logical values. When we index x using it, only the values of x on positions where x &gt; 4 will survive, and these are exactly the values we needed: x = c(3, 2, 5, 3, 1, 5, 6, 4) y = (x &gt; 4) x[y] ## [1] 5 5 6 or, simply, x[x &gt; 4] ## [1] 5 5 6 Indexing can be used to set the values of a vector just as easily x = c(10, 20, 30, 40, 50) x[2:4] = c(0, 1, 2) x ## [1] 10 0 1 2 50 Recycling rules apply in the same way as above x = c(10, 20, 30, 40, 50) x[c(1, 2, 5)] = 7 x ## [1] 7 7 30 40 7 1.2.4 Matrices A matrix in R can be created using the command matrix. The unusual part is that the input is a vector and R populates the components of the matrix by filling it in column by column or row by row. As always, an example will make this clear x = c(1, 2, 3, 4, 5, 6) (A = matrix(x, nrow = 2, ncol = 3, byrow = TRUE)) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 The first argument of the function matrix is the vector which contains all the values. If you want a matrix with m rows and n columns, this vector should be of size \\(m n\\). The arguments ncol and nrow are self-explanatory, and byrow is a logical argument which signals whether to fill by columns or by rows. Here is what happens when we set byrow = FALSE x = c(1, 2, 3, 4, 5, 6) (A = matrix(x, nrow = 2, ncol = 3, byrow = FALSE)) ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 2 4 6 Accessing components of a matrix is as intuitive as it gets (A = matrix(c(1, -1, 7, 2), nrow = 2, ncol = 2)) ## [,1] [,2] ## [1,] 1 7 ## [2,] -1 2 A[1, 2] ## [1] 7 Note that I did not use the argument byrow at all. In such cases, R always uses the default value (documented in the function’s help). For matrix the default value of byrow is FALSE, i.e., it fills the matrix column by column. This is not what we usually want because we tend to think of matrices as composed of rows. Moral: do not forget byrow = TRUE if that is what you, indeed, want. Usual matrix operations can be performed in R in the obvious way (A = matrix(c(1, -1, 7, 2), nrow = 2, ncol = 2)) ## [,1] [,2] ## [1,] 1 7 ## [2,] -1 2 (B = matrix(c(2, 2, -3, -4), nrow = 2, ncol = 2)) ## [,1] [,2] ## [1,] 2 -3 ## [2,] 2 -4 A + B ## [,1] [,2] ## [1,] 3 4 ## [2,] 1 -2 You should be careful with matrix multiplication. The naive operator * yields a matrix, but probably not the one you want (what does * do?) (A = matrix(c(1, 2, 0, 1), nrow = 2, ncol = 2)) ## [,1] [,2] ## [1,] 1 0 ## [2,] 2 1 (B = matrix(c(3, 5, 1, 0), nrow = 2, ncol = 2)) ## [,1] [,2] ## [1,] 3 1 ## [2,] 5 0 A * B ## [,1] [,2] ## [1,] 3 0 ## [2,] 10 0 If you want the matrix product, you have to use %*% A %*% B ## [,1] [,2] ## [1,] 3 1 ## [2,] 11 2 1.2.5 Functions The following syntax is used to define functions in R: my_function = function(x, y, z) { return(x + y + z) } The function my_function returns the sum of its arguments. Having defined it, as above, we can use it like this my_function(1, 3, 9) ## [1] 13 Neither the output nor the arguments of a function in R are restricted to numbers. Our next example function, named winners, takes two vectors as arguments and returns a vector. Its components are those components of the first input vector (x) that are larger than the corresponding components of the second input vector (y) winners = function(x, y) { z = x &gt; y return(x[z]) } winners(c(1, 4, 5, 6, 2), c(2, 3, 3, 9, 2)) ## [1] 4 5 Note how we used several things we learned above in this function. First, we defined the logical vector which indicates where x is larger than y. Then, we used logical indexing to return only certain components of x. 1.2.6 If-else statements Our final element of R is its if-else statement. The syntax of the if statement is if (condition) { statement } where condition is anything that has a logical value, and statement is any R statement. First R evaluates condition. If it is true, it runs statement. If it is false, nothing happens. If you want something to happen if (and only if) your condition is false, you need an if-else statement: if (condition) { statement1 } else { statement2 } This way, statement1 is evaluated when condition is true and statement1 when it is false. Since conditions inside the if statement return logical values, we can combine them using ands, ors or nots. The R notation for these operations is &amp;, | and ! respectively, and to remind you what they do, here is a simple table x y x &amp; y (and) x | y (or) !x (not) TRUE TRUE TRUE TRUE FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE TRUE TRUE FALSE FALSE FALSE FALSE TRUE Let’s put what we learned about functions and if-else statements together to write a function distance_or_zero whose arguments are coordinates x and y of a point in the plane, and whose output is the distance from the point (x,y) to the origin if this distance happens to be between 1 and 2, and and 0 otherwise. We will use similar functions later when we discuss Monte Carlo methods: distance_or_zero = function(x, y) { distance = sqrt(x^2 + y^2) if (distance &lt;= 2 &amp; distance &gt;= 1) { return(distance) } else { return(0) } } distance_or_zero(1.2, 1.6) ## [1] 2 distance_or_zero(2, 3) ## [1] 0 1.3 Problems Here are several simple problems. Their goal is to give you an idea of exactly how much R is required to get started in this course. Problem 1.1 Compute the following (your answer should be a decimal number): \\(1/238746238746\\) \\(2^{45}\\) \\(3^{28}\\) \\(\\sqrt{15}\\) \\(\\cos(\\pi/8)\\)w \\(e^2\\) \\(\\log(2)\\) (the base is \\(e\\)) \\(\\log_{10}(2)\\) (the base is \\(10\\)) \\(\\sqrt[3]{ \\frac{1342.16-2.18}{(3 \\pi +4.12)^2}}\\) Note: some of the answers will look like this 3.14e+13. If you do not know what that means, google E notation. Problem 1.2 Define two variables \\(a\\) and \\(b\\) with values \\(3\\) and \\(4\\) and “put” their product into a variable called \\(c\\). Output the value of \\(c\\). Define two vectors \\(x\\) and \\(y\\) of length \\(3\\), such that the components of \\(x\\) are \\(1,2,3\\) and the components of \\(y\\) are \\(8,9,0\\). Ouput their (componentwise) sum. Define a \\(2\\times 2\\) matrix \\(A=\\begin{pmatrix} 1 &amp; 2 \\\\ -1 &amp; 3 \\end{pmatrix}\\). Compute the matrix square \\(A^2\\). Problem 1.3 Construct a vector \\(x\\) which contains all numbers from \\(1\\) to \\(100\\). Construct a vector \\(y\\) which contains squares of all numbers between \\(20\\) and \\(2000\\). Construct a vector \\(z\\) which contains only those components of \\(y\\) whose values are between \\(400,000\\) and \\(500,000\\). Compute the average (arithmetic mean) of all the components of \\(z\\). There is an R function that does that for you - find it! Problem 1.4 Write a function that takes a numerical argument \\(x\\) and returns \\(5\\) if \\(x\\geq 5\\) and \\(x\\) itself otherwise. Write a function that returns TRUE (a logical value) if its argument is between \\(2\\) and \\(3\\) and FALSE otherwise. (Extra credit) Write a function that takes two equal-sized vectors as arguments and returns the angle between them in degrees. For definiteness, the angle between two vectors is defined to be \\(0\\) when either one of them is \\((0,0,\\dots,0)\\). ⬇︎ In case you were wondering, the text below belongs to footnotes from somewhere high above.⬇︎ it may interfere with your existing installation↩︎ be careful, though. The expression x = y is not the same as x == y. It does not return a logical value - it assigns the value of y to x↩︎ "],
["simulation-of-random-variables-and-monte-carlo.html", "Chapter 2 Simulation of Random Variables and Monte Carlo 2.1 Simulation of some common probability distributions 2.2 Multivariate Distributions 2.3 Additional Problems", " Chapter 2 Simulation of Random Variables and Monte Carlo In the spirit of “learn by doing”, these lecture notes contain many “Problems”. Those with solutions usually introduce new concepts and feature a Comments section right after the solution. These comments are subdivided into R and Math comments focusing on the computational or conceptual features, respectively. Note that you are not expected to be able to do the solved problems before reading their solutions and comments, so don’t worry if you cannot. It is a good practice to try, though. Problems which are left unsolved, however, do not feature any new ideas and are there to help you practice the skills presented before. 2.1 Simulation of some common probability distributions … where we also review some probability along the way. Problem 2.1 ‘’Draw’’ 50 simulations from the geometric distribution with parameter \\(p=0.4\\). Solution: rgeom(50, prob = 0.4) ## [1] 1 0 3 4 1 2 0 0 2 2 0 1 5 0 1 0 2 1 1 0 2 2 2 1 0 0 1 3 2 2 1 1 1 3 5 0 1 1 ## [39] 0 0 0 1 2 0 1 1 1 0 1 0 Comments R: R makes it very easy to simulate draws from a large class of named distributions3, such as geometric, binomial, uniform, normal, etc. For a list of all available distributions, run help(\"distributions\") Each available distribution has an R name; the uniform is unif the normal is norm and the binomial is binom, etc. If you want to simulate \\(n\\) draws (aka a sample of size \\(n\\)) from a distribution, you form a full command by appending the letter r to its R name and use \\(n\\) as an argument. That is how we arrived to rgeom(50) in the solution above. The additional arguments of the function rgeom have to do with the parameters of that distribution. Which parameters go with which distributions, and how to input them as arguments to rgeom or rnorm is best looked up in R’s extensive documentation. Try help(\"rnorm\"), for example. Math: You could spend your whole life trying to understand what it really means to “simulate” or “generate” a random number. The numbers you obtain from so-called random number generators (RNG) are never random. In fact, they are completely deterministically generated. Still, sequences of numbers obtained from (good) random number generators share so many properties with sequences of mythical truly random numbers, that we can use them as if they were truly random. For the purposes of this class, you can assume that the numbers R gives you as random are random enough. Random number generation is a fascinating topic at the intersection of number theory, probability, statistics, computer science and even philosophy, but we do not have the time to cover any of it in this class. If you want to read a story about a particularly bad random number generator, go here. You might have encountered a geometric distribution before. A random variable with that distribution can take any positive integer value or \\(0\\), i.e., its support is \\({\\mathbb N}_0=\\{0,1,2,3,\\dots\\}\\). As you can see from the output above, the value \\(0\\) appears more often than the value \\(3\\), and the value \\(23\\) does not appear at all in this particular simulation run. The probability of seeing the value \\(k\\in \\{0,1,2,3,\\dots\\}\\) as a result of a single draw is given by \\((1-p)^k p\\), where \\(p\\) is called the parameter of the distribution. That corresponds to the following interpretation of the geometric distribution: keep tossing a biased coin (with probability p of obtaining H) until you see the first H; the number Ts before that is that value your geometric random variable4 If we put these probabilities in a single table (and choose \\(p=0.4\\), for example) it is going to look like this: 0 1 2 3 4 5 6 7 … Prob. 0.4 0.24 0.144 0.086 0.052 0.031 0.019 0.011 … Of course, the possible values our random variable can take do not stop at \\(7\\). In fact, there are infinitely many possible values, but we do not have infinite space. Note that even though the value \\(23\\) does not appear in the output of the command rgeom above, it probably would if we simulated many more than \\(50\\) values. Let’s try it with \\(500\\) draws - the table below counts how many \\(0s\\), \\(1s\\), \\(2s\\), etc. we got: 0 1 2 3 4 5 6 7 8 9 10 208 132 62 43 23 16 8 3 2 1 2 Still no luck, but we do observe values above 5 more often. By trial and error, we arrive at about \\(1,000,000\\) as the required number of simulations: 0 1 2 3 … 23 24 25 26 400616 238946 144274 86489 … 3 3 3 3 Problem 2.2 Compute the probability that among \\(1,000,000\\) draws of a geometric random variable with parameter \\(p=0.4\\), we never see a number greater than \\(22\\). Solution: First, we compute the probability that the value seen in a single draw does not exceed \\(22\\): pgeom(22, prob = 0.4) ## [1] 0.9999921 Different draws are independent of each other, so we need to raise this to the power \\(1,000,000\\). (pgeom(22, prob = 0.4))^(1e+06) ## [1] 0.0003717335 Comments: R. The command we used here is pgeom which is a cousin of rgeom. In general, R commands that involve named probability distributions consist of two parts. The prefix, i.e., the initial letter (p in this case) stands for the operation you want to perform, and the rest is the R name of the distribution. There are 4 prefixes, and the commands they produce are Prefix Description r Simulate random draws from the distribution. p Compute the cumulative probability distribution function (cdf) (NOT pdf) d Compute the probability density (pdf) or the probability mass function (pmf) q Compute the quantile function (see the Math section below for the reminder of what these things are). In this problem, we are dealing with a geometric random variable \\(X\\), which has a discrete distribution with support \\(0,1,2,3,\\dots\\). Therefore, the R name is geom. We are interested in the probability \\({\\mathbb{P}}[ X\\leq 22]\\), which corresponds to the cdf of \\(X\\) at \\(x=22\\), so we use the the prefix p. Finally, we used the named parameter p and gave it the value p = 0.4, because the geometric distribution has a single parameter \\(p\\). This problem also gives us a chance to discuss precision. As you can see, the probability of a single draw not exceeding \\(22\\) is very close to \\(1\\). In fact, it is equal to it to 5 decimal places. By default, R displays 7 significant digits of a number. That is enough for most applications (and barely enough for this one), but sometimes we need more. For example, let’s try to compute the probability of seeing no T (tails) in 10 tosses of a biased coin, where the probability of H (heads) is 0.9. 1 - 0.1^10 ## [1] 1 While very close to it, this probability is clearly not equal to \\(1\\), as suggested by the output above. The culprit is the default precision. We can increase the precision (up to \\(22\\) digits) using the options command options(digits = 17) 1 - 0.1^10 ## [1] 0.99999999989999999 Precision issues like this one should not appear in this course, but they will out there “in the wild”, so it might be a good idea to be aware of them. Math. If you forgot all about pdfs, cdfs and such things here is a little reminder: cdf \\(F(x) = {\\mathbb{P}}[X\\leq x]\\) pdf \\(f(x)\\) such that \\({\\mathbb{P}}[X \\in [a,b]] = \\int_a^b f(x) \\, dx\\) for all \\(a&lt;b\\) pmf \\(p(x)\\) such that \\({\\mathbb{P}}[X=a_n] = p(a_n)\\) for some sequence \\(a_n\\) qf \\(q(p)\\) is a number such that \\({\\mathbb{P}}[ X \\leq q(p)] = p\\) Those random variables that admit a pdf are called continuous. The prime examples are the normal, or the exponential distribution. The ones where a pmf exists are called discrete. The sequence \\(a_n\\) covers all values that such a, discrete, random variable can take. Most often, \\(a_n\\) either covers the set of all natural numbers \\(0,1,2,\\dots\\) or a finite subset such as \\(1,2,3,4,5,6\\). Coming back to our original problem, we note that the probability we obtained is quite small. Since \\(1/0.000372\\) is about \\(2690\\), we would have to run about \\(2690\\) rounds of \\(1,000,000\\) simulations before the largest number falls below \\(23\\). Problem 2.3 Compute the \\(0.05\\), \\(0.1\\), \\(0.4\\), \\(0.6\\) and \\(0.95\\) quantiles of the normal distribution with mean \\(1\\) and standard deviation \\(2\\). Solution: qnorm(c(0.05, 0.1, 0.4, 0.6, 0.95), mean = 1, sd = 2) ## [1] -2.2897073 -1.5631031 0.4933058 1.5066942 4.2897073 R. The function we used is qnorm, with the prefix q which computes the quantile function and the R name norm because we are looking for the quantiles of the normal distribution. The additional (named) parameters are where the parameters of the distribution come in (the mean and the standard variation) in this case. Note how we plugged in the entire vector c(0.05, 0.1, 0.4, 0.6, 0.98) instead of a single value into qnorm. You can do that because this function is vectorized. That means that if you give it a vector as an argument, it will “apply itself” to each component of the vector separately, and return the vector of results. Many (but not all) functions in R are vectorized5. As a sanity check, let’s apply pnrom (which computes the cdf of the normal) to these quantile values: p = qnorm(c(0.05, 0.1, 0.4, 0.6, 0.95), mean = 1, sd = 2) pnorm(p, mean = 1, sd = 2) ## [1] 0.05 0.10 0.40 0.60 0.95 As expected, we got the original values back - the normal quantile function and its cdf are inverses of each other. Math. Computing the cdf of a standard normal is the same thing reading a normal table. Computing a quantile is the opposite; you go into the middle of the table and find your value, and then figure out which “Z” would give you that value. Problem 2.4 Simulate \\(60\\) throws of a fair \\(10\\)-sided die. Solution: sample(1:10, 60, replace = TRUE) ## [1] 2 8 9 8 4 7 7 7 2 3 3 10 6 1 9 7 4 7 6 2 2 3 10 1 9 ## [26] 7 3 2 8 4 1 2 8 1 4 9 1 9 10 10 6 1 8 6 1 10 5 1 6 9 ## [51] 8 3 8 9 4 6 1 6 7 8 Comments: Math. Let \\(X\\) denote the outcome of a single throw of a fair \\(10\\)-sided die. The distribution of \\(X\\) is discrete (it can only take the values \\(1,2,\\dots, 10\\)) but it is not one of the more famous named distributions. I guess you could call it a discrete uniform on \\({1,2,\\dots, 10}\\), but a better way to describe such distribution is by a distribution table, which is really just a list of possible values a random variable can take, together with their, respective, probabilities. In this case, 1 2 3 4 5 6 7 8 9 10 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 R. The command used to draw a sample from a (finite) collection is, of, course sample. The first argument is a vector, and it plays the role of the “bag” from which you are drawing. If we are interested in repeated, random samples, we also need to specify replace = FALSE otherwise, you could draw any single number at most once: sample(1:10, 8, replace = FALSE) ## [1] 1 5 6 7 8 10 3 4 With more than 10 draws, we would run out of numbers to draw: sample(1:10, 12, replace = FALSE) ## Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when &#39;replace = FALSE&#39; The bag you draw from can contain objects other than numbers: sample(c(&quot;Picard&quot;, &quot;Data&quot;, &quot;Geordi&quot;), 9, replace = TRUE) ## [1] &quot;Picard&quot; &quot;Data&quot; &quot;Geordi&quot; &quot;Geordi&quot; &quot;Data&quot; &quot;Data&quot; &quot;Picard&quot; &quot;Data&quot; ## [9] &quot;Geordi&quot; So far, each object in the bag had the same probability of being drawn. You can use the sample command to produce a weighted sample, too. For example, if we wanted to simulate \\(10\\) draws from the following distribution 1 2 3 0.2 0.7 0.1 we would use the additional argument prob: sample(c(1, 2, 3), 10, replace = TRUE, prob = c(0.2, 0.7, 0.1)) ## [1] 1 2 2 1 1 2 2 3 2 2 Note how it is mostly \\(2\\)s, as expected. Problem 2.5 Draw a sample of size \\(n=10\\) from \\(N(1,2)\\), i.e., from the normal distribution with parameters \\(\\mu=1\\), \\(\\sigma = 2\\). Plot a histogram of the obtained values. Repeat for \\(n=100\\) and \\(n=100000\\). Solution: x = rnorm(10, mean = 1, sd = 2) hist(x) x = rnorm(100, mean = 1, sd = 2) hist(x) x = rnorm(1e+05, mean = 1, sd = 2) hist(x) Comments: R. It cannot be simpler! You use the command hist, feed it a vector of values, and it produces a histogram. It will even label the axes for you. If you want to learn how to tweak various features of your histogram, type ?hist. Math. Mathematically, histogram can be produced for any (finite) sequence of numbers: we divide the range into several bins, count how many of the points in the sequence falls into each bin, and then draw a bar above that bin whose height is equal (or proportional to) that count. The picture tells use about how the sequence we started from is “distributed”. The order of the points does not matter - you would get exactly the same picture if you sorted the points first. If the sequence of points you draw the histogram of comes from, say, normal distribution, the histogram will resemble the shape of the pdf of a normal distribution. I say resemble, because its shape is ultimately random. If the number of points is small (like in the second part of this problem) the histogram may look nothing like the normal pdf. However, when the number of points gets larger and larger, the shape of the histogram gets closer and closer to the underlying pdf (if it exists). I keep writing “shape” because the three histograms above have very different scales on the \\(y\\) axis. That is because we used counts to set the vertical sizes of bins. A more natural choice is to use the proportions, i.e. relative frequencies (i.e. counts divided by the total number of points) for bar heights. More precisely, the bar height \\(h\\) over the bin \\([a,b]\\) is chosen so that the area of the bar, i.e., \\((b-a)\\times h\\) equals to the proportion of all points that fall inside \\([a,b]\\). This way, the total area under the histogram is always \\(1\\). To draw such a density histogram in R we would need to add the additional option freq = FALSE to hist: x = rnorm(1e+05, mean = 1, sd = 2) hist(x, freq = FALSE) Note how the \\(y\\)-axes label changed from “Frequency” to “Density”. With such a normalization, the histogram of \\(x\\) can be directly compared to the probability density of a normal distribution. Here is a histogram of \\(100,000\\) simulations from our normal distribution with its density function (pdf) superimposed; I am leaving the code in case you are interested: sims = rnorm(10000, mean = 1, sd = 2) x = seq(-6, 8, by = 0.02) y = dnorm(x, mean = 1, sd = 2) hist(sims, freq = FALSE, main = &quot;&quot;) points(x, y, type = &quot;l&quot;, lwd = 3, col = &quot;red&quot;) 2.2 Multivariate Distributions Problem 2.6 Let x contain \\(2,000\\) draws from \\(N(0,1)\\), z another \\(2,000\\) draws from \\(N(0,1)\\) and let y=x^2+z. Draw a scatterplot of x and y to visualize the joint distribution of x and y Plot two histograms, one of x and one of y. Do they tell the whole story about the joint distribution of x and y? Are x and y correlated? Do x and y in your plot “look independent”? Use the permutation test to check of independence between x and y. Solution: 1. x = rnorm(2000) z = rnorm(2000) y = x^2 + z plot(x, y) 2. hist(x) hist(y) No, the two histograms would not be enough to describe the joint distribution. There are many ways in which two random variables \\(X\\) and \\(Y\\) can be jointly distributed, but whose separate (marginal) distributions match the histograms above. To give a very simple example, let \\(X\\) and \\(Y\\) be discrete random variables, each of which can only take values \\(0\\) or \\(1\\). Consider the following two possible joint distribution tables for the random pair \\((X,Y)\\): 0 1 0 0.25 0.25 1 0.25 0.25 0 1 0 0.5 0.0 1 0.0 0.5 In both cases, the marginals are the same, i.e., both \\(X\\) and \\(Y\\) are equally likely to take the value \\(0\\) or \\(1\\), i.e., they both have the Bernoulli distribution with parameter \\(p=1/2\\). That would correspond to the separate histograms to be the same. On the other hand, their joint distributions (aka dependence structures) are completely different. In the first (left) case, \\(X\\) and \\(Y\\) are independent, but in the second they are completely dependent. 3. They are probably not correlated since the sample correlation between x and y is close to \\(0\\): (cor(x, y)) ## [1] -0.02880239 but they do not look independent. To apply the permutation test, we first plot the scatterplot of x vs. y as above. Then, we replace y by a vector with the same components, but randomly permute their positions, and then plot a scatterplot again. We repeat this three times: y_perm_1 = sample(y) y_perm_2 = sample(y) y_perm_3 = sample(y) plot(x, y) plot(x, y_perm_1) plot(x, y_perm_2) plot(x, y_perm_3) The conclusion is clear, the first (upper-left) plot is very different than the other three. Therefore, x and y are probably not independent. Comments. Math. The point of this problem is to review the notion of the joint distribution between two random variables. The most important point here is that there is more to the joint distribution of two random vectors, than just the two distributions taken separately. In a sense, the whole is (much) more than the sum of its parts. This is something that does not happen in the deterministic world. If you give me the \\(x\\)-coordinate of a point, and, separately, its \\(y\\)-coordinate, I will be able to pinpoint the exact location of that point. On the other hand, suppose that the \\(x\\)-coordinate of a point is unknown, so we treat it as a random variable, and suppose that this variable admits the standard normal distribution. Do the same for \\(y\\). Even with this information, you cannot say anything about the position of the point \\((x,y)\\). It could be that the reason we are uncertain about \\(x\\) and the reason we are uncertain about \\(y\\) have nothing to do with each other; in that case we would be right to assume that \\(x\\) and \\(y\\) are independent. If, on the other hand, we got the values of both \\(x\\) and \\(y\\) by measuring them using the same, inaccurate, tape measure, we cannot assume that the errors are independent. It is more likely that both \\(x\\) and \\(y\\) are too big, or both \\(x\\) and \\(y\\) are too small. Mathematically, we say that random variables \\(X\\) and \\(Y\\) are independent if \\[ {\\mathbb{P}}[X \\in [a,b]] \\times {\\mathbb{P}}[ Y \\in [c,d] ] = {\\mathbb{P}}[ X\\in [a,b] \\text{ and } Y\\in [c,d]]\\text{ for all } a,b,c,d.\\] While up to the point, this definition is not very eye-opening, or directly applicable in most cases. Intuitively, \\(X\\) and \\(Y\\) are independent if the distribution of \\(Y\\) would not change if we received additional information about \\(X\\). In our problem, random variables \\(X\\) and \\(Y\\) correspond to vectors x and y. Their scatterplot above clearly conveys the following message: when x is around \\(-2\\), we expect y to be around 4, while when x is around \\(0\\), y would be expected to be around \\(0\\), too. Sometimes, it is not so easy to decide whether two variables are independent by staring at a scatterplot. What would you say about the scatterplot below? The permutation test is designed to help you decide when two (simulated) random variables are likely to be independent. The idea is simple. Suppose that x and y are simulations from two independent (not necessarily identical) distributions; say x=runif(1000) and y=rnorm(1000). The vector y_perm=sample(y) is a randomly permuted version of y (see R section below) and it contains exactly the same information about the distribution of y as y itself does. Both y and y_perm will produce exactly the same histogram. Permuting y, however, “uncouples” it from x. If there was any dependence between the values of x and y before, there certainly isn’t any now. In other the joint distribution of x and y_perm has the same marginals as the joint distribution of x and y, but all the (possible) dependence has been removed. What remains is to compare the scatterplot between x and y and the scatterplot between x and y_perm. If they look about the same, we conclude that x and y are independent. Otherwise, there is some dependence between them. One question remains: why did we have to draw three scatterplots of permuted versions of y? That is because we have only finitely many data points, and it can happen, by pure chance, that the permutation we applied to y does not completely scramble its dependence on x. With a “sample” of three such plots, we get a better feeling for the inherent randomness in this permutation procedure, and it is much easier to tell whether “one of these things is not like the others”. Btw, the random variables in the scatterplot above are, indeed, independent; here are the \\(4\\) permutation-test plots to “prove” it: Unlike univariate (one-variable) distributions which are visualized using histograms or similar plots, multivariate (several-variable) distributions are harder to depict. The most direct relative of the histogram is a 3d histogram. Just like the \\(x\\)-axis is divided into bins in the univariate case, in the multivariate case we divide the \\(xy\\)-plane into regions (squares, e.g.) and count the number of points falling into each of these regions. After that a 3d bar (a skyscraper) is drawn above each square with the height of each skyscraper equal (or proportional) to the number of points which fall into its base. Here is a 3d histogram of our original pair (x,y) from the problem. You should be able to rotate and zoom it right here in the notes, provided your browser has JavaScript enabled: A visualization solution that requires less technology would start the same way, i.e., by dividing the \\(xy\\) plane into regions, but instead of the third dimension, it would use different colors to represent the counts. Here is an example where the regions are hexagons, as opposed to squares; it just looks better, for some reason: Just to showcase the range of possibilities, here is another visualization technique which which requires deeper statistical tools, namely the density contour plot: R. There is very little new R here. You should remember that if x and y are vectors of the same length, plot(x,y) gives you a scatterplot of x and y. To compute the sample correlation between two vectors, use the cor. We used the command sample(y) to obtain a randomly permuted version of y. The simplicity of this is due to default parameters of the command sample which we already learned about. In particular, the default number of samples is exactly the size of the input vector y and, by default, sampling is performed without replacement. If you think about it for a second, you will realize that a sample of size \\(n\\) from the vector of size \\(n\\) without replacement is nothing by a random permutation of y. You are not required to do this in your submissions, but if you want to display several plots side-by-side, use the command is par(mfrow=c(m,n)) before the plot commands. It tells R to plot the next \\(mn\\) plots in a \\(m\\times n\\) grid. 2.3 Additional Problems Problem 2.7 Find the Weibull distribution in R’s help system. Simulate \\(n=10000\\) draws from the Weibull distribution with shape parameter \\(2\\) and scale parameter \\(3\\). Draw a histogram of your simulations. Suppose that the vector x contains \\(n=10000\\) simulations from the standard normal \\(\\mu=0, \\sigma=1)\\). Without simulating any new random numbers, transform it into the vector y such that y is a vector of \\(n=10000\\) simulations from the normal with \\(\\mu=1\\) and \\(\\sigma=0.5\\). Draw histograms of both x and y on the same plot. (Note: the extra parameter add is used to superimpose plots. You may want to use different colors, too. Use the e parameter col for that. ) Starting with x=seq(-3,3,by=0.1), define the appropriate vector y and use x and y to plot the graph of the cdf of the standard normal. The command you want to use is plot with the following extra arguments type=\"l\" (to get a smooth line instead of a bunch of points). main=\"The CDF of the standard normal\" (to set the title), and another argument (which you must look up youself) that will set the \\(y\\)-axis label to \\(F(x)\\). Problem 2.8 Simulate \\(n=1000\\) draws from the distribution whose distribution table is given by 2 4 8 16 0.2 0.3 0.1 0.4 and plot their histogram. You may have learned in probability how to compute the pdf \\(f_Y(y)\\) of a transformation \\(Y=g(X)\\) of a random variable with pdf \\(f_X(x)\\). Suppose that you forgot how to do that, but have access to \\(10,000\\) simulations from the distribution of \\(X\\). How would you get an approximate idea about the shape of the function \\(f_Y\\)? More concretely, take \\(X\\) to be exponentially distributed with parameter \\(1\\) and \\(g(x) = \\sin(x)\\) and produce a picture that approximates the pdf \\(f_Y\\) of \\(Y\\). (Note: even if you remember how to do this analytically, you will run into a difficulty. The function \\(\\sin(x)\\) is not one-to-one and the method usually taught in probability classes will not apply. If you learned how to do it in the many-to-one case of \\(g(x)= \\sin(x)\\), kudos to your instructor!) Let \\(X\\) be a random variable with the Cauchy distribution, and \\(Y = \\operatorname{arctan}(X)\\). R allows you to simulate from the Cauchy distribution, even if you do not know what it is. How would you use that to make an educated guess as to what the distribution of \\(Y\\) is? To make your life easier, consider \\(\\tfrac{2}{\\pi} Y\\) first. Problem 2.9 A basic method for obtaining simulations draws from distributions other than the uniform is the transformation method. The idea is to start with (pseudo) random numbers, i.e., draws from the uniform \\(U(0,1)\\) distribution, and then apply a function \\(g\\) to each simulation. The difficulty is, of course, how to choose the right function \\(g\\). Let \\(X\\) be a random variable with a continuous and strictly increasing cdf \\(F\\). What is the distribution of \\(Y=F(X)\\)? What does that have to do with the transformation method? Problem 2.10 (Extra credit) Let \\(f_1\\) and \\(f_2\\) be two pdfs. We take a constant \\(\\alpha \\in (0,1)\\) and define the function \\(f\\) by \\[ f(x) = \\alpha f_1(x) + (1-\\alpha) f_2(x).\\] The function \\(f\\) is the pdf of a third distribution, which is called the mixture of \\(f_1\\) and \\(f_2\\) with weights \\(\\alpha\\) and \\(1-\\alpha\\). Assuming that you know how to simulate from the distributions with pdfs \\(f_1\\) and \\(f_2\\), how would you draw \\(10,000\\) simulations from the mixture \\(f\\)? Show your method on the example of a mixture of \\(N(0,1)\\) and \\(N(4,1)\\) with \\(\\alpha=2/3\\). Plot the histogram of the obtained sample (play with the parameter breaks until you get a nice picture.) (Hint: start with two vectors, the first containing \\(10,000\\) simulations from \\(f_1\\) and the second from \\(f_2\\). Then “toss” \\(10,000\\) biased coins with \\(\\mathbb{P}[ H ] = \\alpha\\) … ) The double exponential or Laplace distribution is a continuous probability distribution whose pdf is given by \\[ \\tfrac{1}{2} \\exp(-|x|), x\\in {\\mathbb R}.\\] This distribution is not built into R. How would you produce simulations from the double exponential using R? ⬇︎ In case you were wondering, the text below belongs to footnotes from somewhere high above.⬇︎ There are infinitely many ways random variables can be distributed. Indeed, in the discrete \\({\\mathbb N}\\)-valued case only, any sequence of nonnegative numbers \\((p_n)_n\\) such that \\(\\sum_n p_n=1\\) defines a probability distribution. It turns out, however, that a small-ish number of distributions appear in nature much more often then the rest. These distributions, like the normal, uniform, exponential, binomial, etc. turn out to be so important that they each get a name (hence named distributions). ↩︎ Some books will define the geometric random variables as the number of tosses (and not Ts) before the first H is obtained. In that case, the final H is included into the count. Clearly, this definition and the one we have given differ by \\(1\\), and this is really not a big deal, but you have to be careful about what is meant when a geometric random variable is mentioned.↩︎ The function sum adds up all the components of the vector. You would not want such a function to be vectorized. If it were, it would return exactly the same vector it got as input.↩︎ "],
["dist.html", "A Probability Distributions A.1 Discrete distributions: A.2 Continuous distributions:", " A Probability Distributions Here are the basic facts about the probability distributions we will need in these lecture notes. For a much longer list of important distributions, check this wikipedia page. A.1 Discrete distributions: Note: \\((q=1-p)\\) Parameters Notation Support pmf \\({\\mathbb{E}}[X]\\) \\(\\operatorname{Var}[X]\\) Bernoulli \\(p\\in (0,1)\\) \\(B(p)\\) \\(\\{0,1\\}\\) \\((q,p,0,0,\\dots)\\) \\(p\\) \\(pq\\) Binomial \\(n\\in{\\mathbb{N}}, p\\in (0,1)\\) \\(b(n,p)\\) \\(\\{0,1,\\dots, n\\}\\) \\(\\binom{n}{k} p^k q^{n-k}\\) \\(np\\) \\(npq\\) Geometric \\(p\\in (0,1)\\) \\(g(p)\\) \\(\\{0,1,\\dots\\}\\) \\(p q^k\\) \\(q/p\\) \\(q/p^2\\) Poisson \\(\\lambda\\in(0,\\infty)\\) \\(P(\\lambda)\\) \\(\\{0,1,\\dots\\}\\) \\(e^{-\\lambda} \\tfrac{\\lambda^k}{k!}\\) \\(\\lambda\\) \\(\\lambda\\) A.2 Continuous distributions: Note: the pdf is given by the formula in the table only on its support. It is equal to \\(0\\) outside of it. Parameters Notation Support pdf \\({\\mathbb{E}}[X]\\) \\(\\operatorname{Var}[X]\\) Uniform \\(a\\lt b\\) \\(U(a,b)\\) \\((a,b)\\) \\(\\frac{1}{b-a}\\) \\(\\frac{a+b}{2}\\) \\(\\frac{(b-a)^2}{12}\\) Normal \\(\\mu\\in{\\mathbb R},\\sigma \\gt 0\\) \\(N(\\mu,\\sigma)\\) \\({\\mathbb R}\\) \\(\\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2}}\\) \\(\\mu\\) \\(\\sigma^2\\) Exponential \\(\\lambda\\gt 0\\) \\(\\operatorname{Exp}(\\lambda)\\) \\((0,\\infty)\\) \\(\\lambda e^{-\\lambda x}\\) \\(\\tfrac{1}{\\lambda}\\) \\(\\frac{1}{\\lambda^2}\\) "]
]
