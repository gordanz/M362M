[
["simulation-of-random-variables-and-monte-carlo.html", "Chapter 2 Simulation of Random Variables and Monte Carlo 2.1 How to simulate some common probability distributions", " Chapter 2 Simulation of Random Variables and Monte Carlo In the spirit of “learn by doing”, these lecture notes are composed mostly of problems. Those with solutions usually introduce new concepts and feature a Comments section right after the solution. These comments are subdivided into R and Math comments focusing on the computational or coneceptual features, respectively. Note that you are not expected to be able to do the solved problems before reading their solutions and comments, so don’t worry if you cannot. It is a good practice to try, though. Problems unsolved in these notes, however, do not feature any new ideas and are there to help you practice the skills presented before. 2.1 How to simulate some common probability distributions Problem 2.1 ‘’Draw’’ 50 simulations from the geometric distribution with parameter \\(p=0.4\\). Solution: rgeom(50,prob=0.4) #&gt; [1] 1 0 3 4 1 2 0 0 2 2 0 1 5 0 1 0 2 1 1 0 2 2 2 1 0 0 1 3 2 2 1 1 1 3 5 #&gt; [36] 0 1 1 0 0 0 1 2 0 1 1 1 0 1 0 Comments R: R makes it very easy to simulate draws from one of the named distributions, such as geometric, binomial, uniform, normal, etc. For a list of all available distributions, run help(&quot;distributions&quot;) Each available distribution has an R name; the uniform is unif the normal is norm and the binomial is binom, etc. If you want to simulate \\(n\\) draws (aka a sample of size \\(n\\)) from a distribution, you form a full command by appending the letter r to its R name and use \\(n\\) as an argument. That is how we arrived to rgeom(50) in the solution above. The additional arguments of rgeom have to do with the parameters of that distribution. Which parameters go with which distributions, and how to input them as arguments to rgeom or rnorm is best looked up in R’s extensive documentation. Try help(&quot;rnorm&quot;), for example. Math: You might have encountered a geometric distribution before. A random variable with that distribution can take any positive integer value or \\(0\\). As you can see from the output above, the value \\(0\\) appears more often than the value \\(3\\), and the value \\(23\\) does not appear at all. The probability of seeing the value \\(k\\in \\{0,1,2,3,\\dots\\}\\) as a result of a single draw is given by \\((1-p)^k p\\), where \\(p\\) is called the parameter of the distribution. That corresponds to the following interpretation of the geometric distribution: keep tossing a biased coin (with probability \\(p\\) of obtaining H) until you see the first H; the number of tosses yielding T before that is your geometric random variable. If we put these probabilities in a single table (and choose \\(p=0.4\\), for example) it is going to look like this: 0 1 2 3 4 5 6 7 … Prob. 0.4 0.24 0.144 0.086 0.052 0.031 0.019 0.011 … Of course, the possible values our random variable can take do not stop at \\(7\\). In fact, there are infinitely many possible values, but we do not have infinite space. Note that, even though, the value \\(17\\) does not appear in the output of the command rgeom above, it probably would if we simulated more than \\(50\\) values. Let’s try it with \\(500\\) draws: X &lt;- rgeom(500, prob = 0.4) kable(t(table(X))) 0 1 2 3 4 5 6 7 8 9 10 208 132 62 43 23 16 8 3 2 1 2 Still no luck, but we do observe values above 5 more often. By trial and error, we arrive at about \\(1,000,000\\) as the required number of simulations: 0 1 2 3 … 23 24 25 26 400616 238946 144274 86489 … 3 3 3 3 Problem 2.2 Compute the probability that among \\(1,000,000\\) draws of a geometric random variable with parameter \\(p=0.4\\), we never see a number greater than \\(22\\). Solution: First, we compute the probability that the value seen in a single draw does not exceed \\(22\\): pgeom(22,prob=0.4) #&gt; [1] 0.9999921 Different draws are independent of each other, so we need to raise this to the power \\(1,000,000\\). (pgeom(22,prob=0.4))^(1000000) #&gt; [1] 0.0003717335 Comments: R. The command we used here is pgeom which is a cousin of rgeom. In general R commands that involve named probability distributions consist of two parts. The prefix, i.e., the initial letter (p in this case) stands for the operation you want to perform, and the rest is the R name of the distribution. There are 4 prefixes, and the commands they produce are Prefix Description r Simulate random draws from the distribution. p Compute the cumulative probability distribution function (cdf) d Compute the probability density (pdf) or the probability mass function (pmf) q Compute the quantile function (see the Math section below for the reminder of what these things are. ) In this problem, we are dealing with a geometric random variable \\(X\\), which has a discrete distribution, with support \\(0,1,2,3,\\dots\\). Therefore, the R name is geom. We are interested in the probability \\({\\mathbb{P}}[ X\\leq 22]\\), which corresponds to the cdf of \\(X\\) at \\(x=22\\), so we use the the prefix p. Finally, we used the named parameter p and gave it the value p = 0.4, because the geometric distribution has a single parameter \\(p\\). This problem also gives us a chance to discuss precision. As you can see, the probability of a single draw not exceeding \\(22\\) is very close to \\(1\\). In fact, it is equal to it to 5 decimal places. By default, R displays 7 significant digits of a number. That is enough for most applications, but sometimes we need more precision. For example, let’s try to compute the probability of seeing no T (tails) in 10 tosses of a biased coin, where the probability of H (heads) is 0.9. 1-0.1^10 #&gt; [1] 1 While small, this probability is clearly not equal to \\(1\\), as suggested by the output above. The culprit is the default precision. We can increase the precision (up to \\(22\\) digits) by running options(digits=14) options(digits=17) 1-0.1^10 #&gt; [1] 0.99999999989999999 Problems like this should not appear in this course, but they will out there “in the wild”, so it might be a good idea to be aware of them. Math. If you forgot all about pdfs, cdfs and such things here is a little reminder: And here is a reminder what these quantities are: cdf \\(F(x) = {\\mathbb{P}}[X\\leq x]\\) pdf \\(f(x)\\) such that \\(\\int_a^b f(x) \\, dx = {\\mathbb{P}}[X \\in [a,b]]\\) for all \\(a&lt;b\\) pmf \\(p(x)\\) such that \\({\\mathbb{P}}[X=a_n] = p(a_n)\\) for some sequence \\(a_n\\) qf \\(q(p)\\) is a number such that \\({\\mathbb{P}}[ X \\leq q(p)] = p\\) Those random variables that admit a pdf are called continuous. The prime examples are the normal, or the exponential distribution. The ones where a pmf exists are called discrete. The sequence \\(a_n\\) is simply the sequence of all values that such a, discrete, random variable can take. Most often, \\(a_n\\) is either the set of all natural numbers \\(0,1,2,\\dots\\) or a finite subset such that \\(0,1,2,3,4,5\\), called the support of the distribution. Btw, this probability we obtained is quite small. Since \\(1/0.000372\\) is about \\(2690\\), we would have to run about \\(2690\\) rounds of \\(1,000,000\\) simulations before the largest number falls below \\(23\\). Problem 2.3 Compute the \\(0.05\\), \\(0.1\\), \\(0.4\\), \\(0.6\\) and \\(0.95\\) quantiles of the normal distribution with mean \\(1\\) and standard deviation \\(2\\). Solution: qnorm( c(0.05, 0.1, 0.4, 0.6, 0.95), mean = 1, sd = 2) #&gt; [1] -2.2897073 -1.5631031 0.4933058 1.5066942 4.2897073 R. The function we used is qnorm, with the prefix q which computes the quantile function and the R name norm because we are looking for the quantiles of the normal distribution. The additinal (named) parameters are where the parameters of the distribution come in (the mean and the standard variation) in this case. Note how we plugged in the entire vector c(0.05, 0.1, 0.4, 0.6, 0.98) instead of a single value into qnorm. You can do that because this function is vectorized. That means that if you give it a vector as an argument, it will return a vector with values corresponding to each element of the input. Many (but not all) functions in R are vectorized. As a sanity check, let’s apply the cdf to these quantile values: p &lt;- qnorm( c(0.05, 0.1, 0.4, 0.6, 0.95), mean = 1, sd = 2) pnorm( p , mean = 1, sd = 2) #&gt; [1] 0.05 0.10 0.40 0.60 0.95 As expected, we got the original values back - the normal quantile function and its cdf are inverses of each other. Problem 2.4 Simulate \\(60\\) throws of a fair \\(10\\)-sided die. Solution: sample( 1:10 , 60, replace = TRUE) #&gt; [1] 2 8 9 8 4 7 7 7 2 3 3 10 6 1 9 7 4 7 6 2 2 3 10 #&gt; [24] 1 9 7 3 2 8 4 1 2 8 1 4 9 1 9 10 10 6 1 8 6 1 10 #&gt; [47] 5 1 6 9 8 3 8 9 4 6 1 6 7 8 Comments: Math. Let \\(X\\) denote the outcome of a single throw of this strange die. The distribution of \\(X\\) is discrete (it can only take the values \\(1,2,\\dots, n\\)) but it is not one of the named distributions. The way we describe such distribution is by a distribution table, which is really just a list of possible values a random variable can take, together with their, respective, probabilities. 1 2 3 4 5 6 7 8 9 10 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 R. The command used to draw a sample from a (finite) collection is, of, course sample. The first argument is a vector, and it contains the “bag” from which you are drawing. If we are interested in repeated, random samples, we also need to specity replace = FALSE otherwise, you could draw any signle number am most once: sample(1:10, 8, replace = FALSE) #&gt; [1] 1 5 6 7 8 10 3 4 With more than 10 draws, we would run out of numbers to draw: sample(1:10, 12, replace = FALSE) #&gt; Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when &#39;replace = FALSE&#39; The bag you draw from can contain objects other than numbers: sample( c(&quot;Alice&quot;, &quot;Bob&quot;, &quot;Charlie&quot;), 8, replace = TRUE) #&gt; [1] &quot;Charlie&quot; &quot;Bob&quot; &quot;Alice&quot; &quot;Charlie&quot; &quot;Bob&quot; &quot;Charlie&quot; &quot;Charlie&quot; #&gt; [8] &quot;Charlie&quot; So far, each object in the bag had the same probability of being drawn. You can use the sample command to produce a weighted sample, too. For example, if we wanted to simulate \\(10\\) draws from the following distribution 1 2 3 0.2 0.7 0.1 we would use the additional argument prob: sample( c(1,2,3), 10, replace = TRUE, prob = c(0.2,0.7, 0.1)) #&gt; [1] 2 2 2 2 1 2 2 2 2 1 Note how it is mostly \\(2\\)s. Problem 2.5 Draw a sample of \\(n=100\\) from the normal distribution with parameters \\(\\mu=1\\), \\(\\sigma = 2\\). Plot a historgram of the obtained values. Repeat \\(n=10\\) and \\(n=100000\\). Solution: x = rnorm(100, mean = 1, sd = 2) hist(x) x = rnorm(10, mean = 1, sd = 2) hist(x) x = rnorm(1000000, mean = 1, sd = 2) hist(x) Comments: R. It cannot be simpler. You use the command hist, feed it a vector of values, and it produces a histogram. It will even labels the axes. If you want to learn how to tweak various features of your histogram, type ?hist. Esthetically, the built-in histograms leave something to be desired. We can do better, using the package ggplot2. You don’t have to use it in this class, but if you want to, you install it first by running install.packages(&quot;ggplot2&quot;) (you have to do this only once). Then, every time you want to use it, you run library(ggplot2) to notify R that you are aobut to use a function from that package. It would take a whole semester to learn everything there is to know about ggplot2; I will only show what a histogram looks like in it: library(ggplot2) x = rnorm(100000, mean = 1, sd = 2) qplot(x, bins=40) Math. Mathematically, histogram can be produced for any (finite) sequence of numbers: we divide the range into several bins, count how many of the points in the sequence falls into which bin, and then draw a bar above that bin whose height is equal (or proportional to) that count. The picture tells use about how the sequence we started from is “distributed”. The order of the points does not matter - you would get exactly the same picture if you presorted the points. If the sequence of points you draw the histogram comes from, say, normal distribution, the histogram will resemble the shape of the pdf of a normal distribution. I say resemble, because its shape is ultimately random. If the number of points is small (like in the second part of this problem) the histogram may look nothing like the normal pdf. However, when the number of points gets larger and larger, the shape of the histogram gets closer and closer to the underlying pdf (if it exists). I keep writing “shape” because the the three histograms above have very different scales on the \\(y\\) axis. That is because we used counts to set the sizes of bins. A more natural choice is to use the proportions, i.e. relative frequencies (i.e. counts divided by the total number of points) for bar heights. In R, we would need to add an additional option to hist: x = rnorm(100000, mean = 1, sd = 2) hist(x,freq = FALSE) With such a normalization, the histogram of \\(x\\) can be directly compared to the probability density of a normal distribution. Here is a picture. Its R code is a little bit too advanced for now, so I am skipping it: "]
]
